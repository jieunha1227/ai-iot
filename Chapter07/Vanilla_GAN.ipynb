{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/am/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# import the necessaey modules\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from tensorflow.contrib.layers import xavier_initializer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "# define hyperparameters\n",
    "batch_size = 128\n",
    "Z_dim = 100\n",
    "im_size = 28\n",
    "h_size=128\n",
    "learning_rate_D = .0005\n",
    "learning_rate_G = .0006\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Placeholder for input X and random noise Z\n",
    "X = tf.placeholder(tf.float32, shape=[None, im_size*im_size])\n",
    "Z = tf.placeholder(tf.float32, shape=[None, Z_dim])\n",
    "initializer=xavier_initializer()\n",
    "\n",
    "# Define Discriminator and Generator training variables\n",
    "\n",
    "#Discriminiator\n",
    "D_W1 = tf.Variable(initializer([im_size*im_size, h_size]))\n",
    "D_b1 = tf.Variable(tf.zeros(shape=[h_size]))\n",
    "\n",
    "D_W2 = tf.Variable(initializer([h_size, 1]))\n",
    "D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_b1, D_b2]\n",
    "\n",
    "#Generator\n",
    "G_W1 = tf.Variable(initializer([Z_dim, h_size]))\n",
    "G_b1 = tf.Variable(tf.zeros(shape=[h_size]))\n",
    "\n",
    "G_W2 = tf.Variable(initializer([h_size, im_size*im_size]))\n",
    "G_b2 = tf.Variable(tf.zeros(shape=[im_size*im_size]))\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_b1, G_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n])\n",
    "\n",
    "\n",
    "def generator(z):\n",
    "    \"\"\" Two layer Generator Network Z=>128=>784 \"\"\"\n",
    "    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n",
    "    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2\n",
    "    G_prob = tf.nn.sigmoid(G_log_prob)\n",
    "\n",
    "    return G_prob\n",
    "\n",
    "\n",
    "def discriminator(x):\n",
    "    \"\"\" Two layer Discriminator Network X=>128=>1 \"\"\"\n",
    "    D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)\n",
    "    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
    "    D_prob = tf.nn.sigmoid(D_logit)\n",
    "\n",
    "    return D_prob, D_logit\n",
    "\n",
    "\n",
    "def plot(samples):\n",
    "    \"function to plot generated samples\"\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    gs = gridspec.GridSpec(5, 5)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='gray')\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_sample = generator(Z)\n",
    "D_real, D_logit_real = discriminator(X)\n",
    "D_fake, D_logit_fake = discriminator(G_sample)\n",
    "\n",
    "# losses:\n",
    "# -------------------\n",
    "D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
    "D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
    "D_loss = D_loss_real + D_loss_fake\n",
    "G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))\n",
    "\n",
    "D_solver = tf.train.AdamOptimizer(learning_rate=learning_rate_D).minimize(D_loss, var_list=theta_D)\n",
    "G_solver = tf.train.AdamOptimizer(learning_rate=learning_rate_G).minimize(G_loss, var_list=theta_G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0 D loss: 1.085 G_loss: 1.998\n",
      "Iter: 100 D loss: 0.08578 G_loss: 5.416\n",
      "Iter: 200 D loss: 0.3299 G_loss: 3.09\n",
      "Iter: 300 D loss: 0.2034 G_loss: 3.862\n",
      "Iter: 400 D loss: 0.08722 G_loss: 4.015\n",
      "Iter: 500 D loss: 0.0238 G_loss: 4.706\n",
      "Iter: 600 D loss: 0.03654 G_loss: 4.905\n",
      "Iter: 700 D loss: 0.03494 G_loss: 4.825\n",
      "Iter: 800 D loss: 0.02324 G_loss: 5.374\n",
      "Iter: 900 D loss: 0.01525 G_loss: 5.616\n",
      "Iter: 1000 D loss: 0.05434 G_loss: 5.536\n",
      "Iter: 1100 D loss: 0.02404 G_loss: 5.85\n",
      "Iter: 1200 D loss: 0.02222 G_loss: 5.645\n",
      "Iter: 1300 D loss: 0.04074 G_loss: 6.221\n",
      "Iter: 1400 D loss: 0.02187 G_loss: 7.705\n",
      "Iter: 1500 D loss: 0.01162 G_loss: 7.475\n",
      "Iter: 1600 D loss: 0.02001 G_loss: 6.783\n",
      "Iter: 1700 D loss: 0.0304 G_loss: 5.056\n",
      "Iter: 1800 D loss: 0.04932 G_loss: 4.444\n",
      "Iter: 1900 D loss: 0.1955 G_loss: 3.668\n",
      "Iter: 2000 D loss: 0.1255 G_loss: 3.648\n",
      "Iter: 2100 D loss: 0.1186 G_loss: 4.202\n",
      "Iter: 2200 D loss: 0.08755 G_loss: 4.632\n",
      "Iter: 2300 D loss: 0.02271 G_loss: 5.845\n",
      "Iter: 2400 D loss: 0.02847 G_loss: 5.701\n",
      "Iter: 2500 D loss: 0.05908 G_loss: 4.446\n",
      "Iter: 2600 D loss: 0.0739 G_loss: 4.721\n",
      "Iter: 2700 D loss: 0.1393 G_loss: 3.782\n",
      "Iter: 2800 D loss: 0.0663 G_loss: 4.012\n",
      "Iter: 2900 D loss: 0.08499 G_loss: 3.505\n",
      "Iter: 3000 D loss: 0.1775 G_loss: 3.69\n",
      "Iter: 3100 D loss: 0.2666 G_loss: 3.042\n",
      "Iter: 3200 D loss: 0.2255 G_loss: 3.73\n",
      "Iter: 3300 D loss: 0.1257 G_loss: 4.218\n",
      "Iter: 3400 D loss: 0.2243 G_loss: 3.458\n",
      "Iter: 3500 D loss: 0.2149 G_loss: 3.301\n",
      "Iter: 3600 D loss: 0.1256 G_loss: 3.868\n",
      "Iter: 3700 D loss: 0.1786 G_loss: 3.66\n",
      "Iter: 3800 D loss: 0.07334 G_loss: 4.084\n",
      "Iter: 3900 D loss: 0.1077 G_loss: 3.694\n",
      "Iter: 4000 D loss: 0.08733 G_loss: 4.537\n",
      "Iter: 4100 D loss: 0.1312 G_loss: 3.95\n",
      "Iter: 4200 D loss: 0.1614 G_loss: 4.36\n",
      "Iter: 4300 D loss: 0.102 G_loss: 5.054\n",
      "Iter: 4400 D loss: 0.1652 G_loss: 3.961\n",
      "Iter: 4500 D loss: 0.1919 G_loss: 4.756\n",
      "Iter: 4600 D loss: 0.1714 G_loss: 4.509\n",
      "Iter: 4700 D loss: 0.09827 G_loss: 4.501\n",
      "Iter: 4800 D loss: 0.1532 G_loss: 4.217\n",
      "Iter: 4900 D loss: 0.2116 G_loss: 4.278\n",
      "Iter: 5000 D loss: 0.1564 G_loss: 4.006\n",
      "Iter: 5100 D loss: 0.2071 G_loss: 4.28\n",
      "Iter: 5200 D loss: 0.08608 G_loss: 4.46\n",
      "Iter: 5300 D loss: 0.1575 G_loss: 4.479\n",
      "Iter: 5400 D loss: 0.1795 G_loss: 3.972\n",
      "Iter: 5500 D loss: 0.1047 G_loss: 4.145\n",
      "Iter: 5600 D loss: 0.2058 G_loss: 3.744\n",
      "Iter: 5700 D loss: 0.1653 G_loss: 4.734\n",
      "Iter: 5800 D loss: 0.2242 G_loss: 3.968\n",
      "Iter: 5900 D loss: 0.4463 G_loss: 3.393\n",
      "Iter: 6000 D loss: 0.2763 G_loss: 3.773\n",
      "Iter: 6100 D loss: 0.2132 G_loss: 4.774\n",
      "Iter: 6200 D loss: 0.2612 G_loss: 3.78\n",
      "Iter: 6300 D loss: 0.1287 G_loss: 4.436\n",
      "Iter: 6400 D loss: 0.3588 G_loss: 3.632\n",
      "Iter: 6500 D loss: 0.4633 G_loss: 3.663\n",
      "Iter: 6600 D loss: 0.2262 G_loss: 3.651\n",
      "Iter: 6700 D loss: 0.2362 G_loss: 4.261\n",
      "Iter: 6800 D loss: 0.2953 G_loss: 3.822\n",
      "Iter: 6900 D loss: 0.1459 G_loss: 4.178\n",
      "Iter: 7000 D loss: 0.321 G_loss: 4.062\n",
      "Iter: 7100 D loss: 0.3768 G_loss: 3.991\n",
      "Iter: 7200 D loss: 0.2891 G_loss: 3.363\n",
      "Iter: 7300 D loss: 0.2863 G_loss: 3.255\n",
      "Iter: 7400 D loss: 0.516 G_loss: 3.333\n",
      "Iter: 7500 D loss: 0.4223 G_loss: 3.013\n",
      "Iter: 7600 D loss: 0.3306 G_loss: 3.663\n",
      "Iter: 7700 D loss: 0.3809 G_loss: 3.545\n",
      "Iter: 7800 D loss: 0.2839 G_loss: 3.372\n",
      "Iter: 7900 D loss: 0.219 G_loss: 3.672\n",
      "Iter: 8000 D loss: 0.2198 G_loss: 3.491\n",
      "Iter: 8100 D loss: 0.2394 G_loss: 3.732\n",
      "Iter: 8200 D loss: 0.5391 G_loss: 3.721\n",
      "Iter: 8300 D loss: 0.4642 G_loss: 3.29\n",
      "Iter: 8400 D loss: 0.2028 G_loss: 3.955\n",
      "Iter: 8500 D loss: 0.5251 G_loss: 3.114\n",
      "Iter: 8600 D loss: 0.3205 G_loss: 4.29\n",
      "Iter: 8700 D loss: 0.3647 G_loss: 2.903\n",
      "Iter: 8800 D loss: 0.4329 G_loss: 3.309\n",
      "Iter: 8900 D loss: 0.2956 G_loss: 3.333\n",
      "Iter: 9000 D loss: 0.5227 G_loss: 3.092\n",
      "Iter: 9100 D loss: 0.4025 G_loss: 3.089\n",
      "Iter: 9200 D loss: 0.4711 G_loss: 3.209\n",
      "Iter: 9300 D loss: 0.6455 G_loss: 2.775\n",
      "Iter: 9400 D loss: 0.4149 G_loss: 3.546\n",
      "Iter: 9500 D loss: 0.4949 G_loss: 3.18\n",
      "Iter: 9600 D loss: 0.4372 G_loss: 3.309\n",
      "Iter: 9700 D loss: 0.5998 G_loss: 2.961\n",
      "Iter: 9800 D loss: 0.4295 G_loss: 2.917\n",
      "Iter: 9900 D loss: 0.4897 G_loss: 3.267\n",
      "Iter: 10000 D loss: 0.4655 G_loss: 3.342\n",
      "Iter: 10100 D loss: 0.6353 G_loss: 2.821\n",
      "Iter: 10200 D loss: 0.2997 G_loss: 3.065\n",
      "Iter: 10300 D loss: 0.5815 G_loss: 3.204\n",
      "Iter: 10400 D loss: 0.5681 G_loss: 2.36\n",
      "Iter: 10500 D loss: 0.4335 G_loss: 3.733\n",
      "Iter: 10600 D loss: 0.5384 G_loss: 3.361\n",
      "Iter: 10700 D loss: 0.3203 G_loss: 3.307\n",
      "Iter: 10800 D loss: 0.3403 G_loss: 3.173\n",
      "Iter: 10900 D loss: 0.4989 G_loss: 2.879\n",
      "Iter: 11000 D loss: 0.4372 G_loss: 3.34\n",
      "Iter: 11100 D loss: 0.5605 G_loss: 2.793\n",
      "Iter: 11200 D loss: 0.6259 G_loss: 3.366\n",
      "Iter: 11300 D loss: 0.3866 G_loss: 3.091\n",
      "Iter: 11400 D loss: 0.7377 G_loss: 3.084\n",
      "Iter: 11500 D loss: 0.499 G_loss: 3.223\n",
      "Iter: 11600 D loss: 0.5495 G_loss: 2.668\n",
      "Iter: 11700 D loss: 0.4605 G_loss: 2.964\n",
      "Iter: 11800 D loss: 0.82 G_loss: 3.15\n",
      "Iter: 11900 D loss: 0.6119 G_loss: 3.188\n",
      "Iter: 12000 D loss: 0.5629 G_loss: 3.119\n",
      "Iter: 12100 D loss: 0.5858 G_loss: 2.855\n",
      "Iter: 12200 D loss: 0.4601 G_loss: 2.745\n",
      "Iter: 12300 D loss: 0.471 G_loss: 2.693\n",
      "Iter: 12400 D loss: 0.5856 G_loss: 2.689\n",
      "Iter: 12500 D loss: 0.5906 G_loss: 3.177\n",
      "Iter: 12600 D loss: 0.5937 G_loss: 2.693\n",
      "Iter: 12700 D loss: 0.5364 G_loss: 2.57\n",
      "Iter: 12800 D loss: 0.5759 G_loss: 2.737\n",
      "Iter: 12900 D loss: 0.681 G_loss: 2.659\n",
      "Iter: 13000 D loss: 0.5344 G_loss: 2.466\n",
      "Iter: 13100 D loss: 0.5885 G_loss: 2.769\n",
      "Iter: 13200 D loss: 0.6074 G_loss: 2.679\n",
      "Iter: 13300 D loss: 0.5129 G_loss: 2.902\n",
      "Iter: 13400 D loss: 0.743 G_loss: 2.261\n",
      "Iter: 13500 D loss: 0.6267 G_loss: 3.053\n",
      "Iter: 13600 D loss: 0.4933 G_loss: 2.647\n",
      "Iter: 13700 D loss: 0.5172 G_loss: 2.528\n",
      "Iter: 13800 D loss: 0.4655 G_loss: 2.821\n",
      "Iter: 13900 D loss: 0.6552 G_loss: 2.597\n",
      "Iter: 14000 D loss: 0.538 G_loss: 2.712\n",
      "Iter: 14100 D loss: 0.6406 G_loss: 2.79\n",
      "Iter: 14200 D loss: 0.6783 G_loss: 2.89\n",
      "Iter: 14300 D loss: 0.8369 G_loss: 2.737\n",
      "Iter: 14400 D loss: 0.5428 G_loss: 3.252\n",
      "Iter: 14500 D loss: 0.7431 G_loss: 2.78\n",
      "Iter: 14600 D loss: 0.591 G_loss: 2.573\n",
      "Iter: 14700 D loss: 0.839 G_loss: 2.111\n",
      "Iter: 14800 D loss: 0.5027 G_loss: 2.648\n",
      "Iter: 14900 D loss: 0.7688 G_loss: 2.382\n",
      "Iter: 15000 D loss: 0.5235 G_loss: 2.783\n",
      "Iter: 15100 D loss: 0.7053 G_loss: 2.357\n",
      "Iter: 15200 D loss: 0.6728 G_loss: 2.522\n",
      "Iter: 15300 D loss: 0.8575 G_loss: 2.631\n",
      "Iter: 15400 D loss: 0.6973 G_loss: 2.058\n",
      "Iter: 15500 D loss: 0.596 G_loss: 2.532\n",
      "Iter: 15600 D loss: 0.6252 G_loss: 2.511\n",
      "Iter: 15700 D loss: 0.7835 G_loss: 2.496\n",
      "Iter: 15800 D loss: 0.7047 G_loss: 2.51\n",
      "Iter: 15900 D loss: 0.8377 G_loss: 2.397\n",
      "Iter: 16000 D loss: 0.6017 G_loss: 2.728\n",
      "Iter: 16100 D loss: 0.5976 G_loss: 2.496\n",
      "Iter: 16200 D loss: 0.6189 G_loss: 2.858\n",
      "Iter: 16300 D loss: 0.6137 G_loss: 2.136\n",
      "Iter: 16400 D loss: 0.7154 G_loss: 2.022\n",
      "Iter: 16500 D loss: 0.7953 G_loss: 2.381\n",
      "Iter: 16600 D loss: 0.6901 G_loss: 2.184\n",
      "Iter: 16700 D loss: 0.7978 G_loss: 2.121\n",
      "Iter: 16800 D loss: 0.7162 G_loss: 2.288\n",
      "Iter: 16900 D loss: 0.573 G_loss: 2.094\n",
      "Iter: 17000 D loss: 0.5801 G_loss: 2.18\n",
      "Iter: 17100 D loss: 0.7762 G_loss: 2.052\n",
      "Iter: 17200 D loss: 0.8346 G_loss: 2.104\n",
      "Iter: 17300 D loss: 0.9324 G_loss: 2.227\n",
      "Iter: 17400 D loss: 0.8689 G_loss: 1.819\n",
      "Iter: 17500 D loss: 0.5686 G_loss: 2.363\n",
      "Iter: 17600 D loss: 0.8392 G_loss: 2.068\n",
      "Iter: 17700 D loss: 0.6784 G_loss: 2.218\n",
      "Iter: 17800 D loss: 0.7347 G_loss: 2.366\n",
      "Iter: 17900 D loss: 0.7776 G_loss: 2.23\n",
      "Iter: 18000 D loss: 0.7547 G_loss: 2.233\n",
      "Iter: 18100 D loss: 0.7096 G_loss: 1.966\n",
      "Iter: 18200 D loss: 0.7464 G_loss: 2.094\n",
      "Iter: 18300 D loss: 0.7914 G_loss: 2.1\n",
      "Iter: 18400 D loss: 0.7013 G_loss: 2.334\n",
      "Iter: 18500 D loss: 0.8024 G_loss: 2.169\n",
      "Iter: 18600 D loss: 0.8884 G_loss: 2.001\n",
      "Iter: 18700 D loss: 0.6843 G_loss: 2.121\n",
      "Iter: 18800 D loss: 0.6207 G_loss: 2.218\n",
      "Iter: 18900 D loss: 0.7601 G_loss: 2.124\n",
      "Iter: 19000 D loss: 0.8055 G_loss: 2.19\n",
      "Iter: 19100 D loss: 0.8653 G_loss: 2.338\n",
      "Iter: 19200 D loss: 0.6653 G_loss: 2.09\n",
      "Iter: 19300 D loss: 0.8087 G_loss: 2.102\n",
      "Iter: 19400 D loss: 0.8851 G_loss: 2.287\n",
      "Iter: 19500 D loss: 0.8585 G_loss: 2.109\n",
      "Iter: 19600 D loss: 0.853 G_loss: 2.033\n",
      "Iter: 19700 D loss: 0.7848 G_loss: 1.841\n",
      "Iter: 19800 D loss: 0.7045 G_loss: 1.983\n",
      "Iter: 19900 D loss: 0.9413 G_loss: 1.837\n",
      "Iter: 20000 D loss: 0.7776 G_loss: 2.168\n",
      "Iter: 20100 D loss: 0.8817 G_loss: 2.16\n",
      "Iter: 20200 D loss: 0.7624 G_loss: 2.204\n",
      "Iter: 20300 D loss: 0.7449 G_loss: 2.292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 20400 D loss: 0.6668 G_loss: 2.008\n",
      "Iter: 20500 D loss: 0.7854 G_loss: 1.732\n",
      "Iter: 20600 D loss: 0.7713 G_loss: 2.296\n",
      "Iter: 20700 D loss: 0.7764 G_loss: 2.038\n",
      "Iter: 20800 D loss: 0.7515 G_loss: 1.832\n",
      "Iter: 20900 D loss: 0.7285 G_loss: 2.079\n",
      "Iter: 21000 D loss: 0.7964 G_loss: 1.952\n",
      "Iter: 21100 D loss: 0.713 G_loss: 1.893\n",
      "Iter: 21200 D loss: 0.6619 G_loss: 1.937\n",
      "Iter: 21300 D loss: 0.7075 G_loss: 2.04\n",
      "Iter: 21400 D loss: 0.5833 G_loss: 1.867\n",
      "Iter: 21500 D loss: 0.8153 G_loss: 2.214\n",
      "Iter: 21600 D loss: 0.7344 G_loss: 1.98\n",
      "Iter: 21700 D loss: 0.7672 G_loss: 1.982\n",
      "Iter: 21800 D loss: 0.7236 G_loss: 1.928\n",
      "Iter: 21900 D loss: 0.7126 G_loss: 1.9\n",
      "Iter: 22000 D loss: 0.8475 G_loss: 1.785\n",
      "Iter: 22100 D loss: 0.6677 G_loss: 2.229\n",
      "Iter: 22200 D loss: 0.7141 G_loss: 1.692\n",
      "Iter: 22300 D loss: 0.843 G_loss: 2.114\n",
      "Iter: 22400 D loss: 0.6722 G_loss: 2.32\n",
      "Iter: 22500 D loss: 0.7872 G_loss: 2.13\n",
      "Iter: 22600 D loss: 0.8489 G_loss: 1.942\n",
      "Iter: 22700 D loss: 0.6893 G_loss: 2.118\n",
      "Iter: 22800 D loss: 0.74 G_loss: 1.921\n",
      "Iter: 22900 D loss: 0.8028 G_loss: 1.931\n",
      "Iter: 23000 D loss: 0.8563 G_loss: 1.816\n",
      "Iter: 23100 D loss: 0.6897 G_loss: 2.109\n",
      "Iter: 23200 D loss: 0.7534 G_loss: 1.731\n",
      "Iter: 23300 D loss: 0.7744 G_loss: 2.109\n",
      "Iter: 23400 D loss: 0.6164 G_loss: 1.879\n",
      "Iter: 23500 D loss: 0.847 G_loss: 2.088\n",
      "Iter: 23600 D loss: 0.7849 G_loss: 1.917\n",
      "Iter: 23700 D loss: 0.6949 G_loss: 2.065\n",
      "Iter: 23800 D loss: 0.8719 G_loss: 1.75\n",
      "Iter: 23900 D loss: 0.7511 G_loss: 1.865\n",
      "Iter: 24000 D loss: 0.9575 G_loss: 1.642\n",
      "Iter: 24100 D loss: 0.8724 G_loss: 1.882\n",
      "Iter: 24200 D loss: 0.6692 G_loss: 1.962\n",
      "Iter: 24300 D loss: 0.9738 G_loss: 1.841\n",
      "Iter: 24400 D loss: 0.7599 G_loss: 1.982\n",
      "Iter: 24500 D loss: 0.7276 G_loss: 2.174\n",
      "Iter: 24600 D loss: 0.8123 G_loss: 1.68\n",
      "Iter: 24700 D loss: 0.7458 G_loss: 1.898\n",
      "Iter: 24800 D loss: 0.811 G_loss: 2.014\n",
      "Iter: 24900 D loss: 0.7711 G_loss: 2.226\n",
      "Iter: 25000 D loss: 0.8277 G_loss: 1.664\n",
      "Iter: 25100 D loss: 0.7233 G_loss: 2.122\n",
      "Iter: 25200 D loss: 0.6944 G_loss: 1.83\n",
      "Iter: 25300 D loss: 0.6932 G_loss: 1.989\n",
      "Iter: 25400 D loss: 0.6257 G_loss: 2.087\n",
      "Iter: 25500 D loss: 0.8836 G_loss: 1.875\n",
      "Iter: 25600 D loss: 0.7647 G_loss: 2.152\n",
      "Iter: 25700 D loss: 0.7747 G_loss: 1.868\n",
      "Iter: 25800 D loss: 0.7195 G_loss: 1.922\n",
      "Iter: 25900 D loss: 0.8123 G_loss: 1.699\n",
      "Iter: 26000 D loss: 0.8003 G_loss: 1.914\n",
      "Iter: 26100 D loss: 0.7197 G_loss: 1.86\n",
      "Iter: 26200 D loss: 0.863 G_loss: 1.689\n",
      "Iter: 26300 D loss: 0.7876 G_loss: 1.656\n",
      "Iter: 26400 D loss: 0.7214 G_loss: 2.111\n",
      "Iter: 26500 D loss: 0.8779 G_loss: 1.832\n",
      "Iter: 26600 D loss: 0.7379 G_loss: 1.948\n",
      "Iter: 26700 D loss: 0.8977 G_loss: 2.087\n",
      "Iter: 26800 D loss: 0.7016 G_loss: 2.315\n",
      "Iter: 26900 D loss: 0.6448 G_loss: 1.92\n",
      "Iter: 27000 D loss: 0.6912 G_loss: 1.945\n",
      "Iter: 27100 D loss: 0.8401 G_loss: 1.856\n",
      "Iter: 27200 D loss: 0.8425 G_loss: 1.875\n",
      "Iter: 27300 D loss: 0.7539 G_loss: 1.833\n",
      "Iter: 27400 D loss: 0.8438 G_loss: 1.688\n",
      "Iter: 27500 D loss: 0.7615 G_loss: 1.813\n",
      "Iter: 27600 D loss: 0.6468 G_loss: 2.041\n",
      "Iter: 27700 D loss: 0.9336 G_loss: 1.852\n",
      "Iter: 27800 D loss: 0.7896 G_loss: 1.952\n",
      "Iter: 27900 D loss: 0.7521 G_loss: 2.132\n",
      "Iter: 28000 D loss: 0.7922 G_loss: 1.858\n",
      "Iter: 28100 D loss: 0.8462 G_loss: 2.012\n",
      "Iter: 28200 D loss: 0.7113 G_loss: 1.997\n",
      "Iter: 28300 D loss: 0.7358 G_loss: 1.864\n",
      "Iter: 28400 D loss: 0.8371 G_loss: 2.033\n",
      "Iter: 28500 D loss: 0.857 G_loss: 1.674\n",
      "Iter: 28600 D loss: 0.7073 G_loss: 2.083\n",
      "Iter: 28700 D loss: 0.7839 G_loss: 1.875\n",
      "Iter: 28800 D loss: 0.7239 G_loss: 1.976\n",
      "Iter: 28900 D loss: 0.6656 G_loss: 1.907\n",
      "Iter: 29000 D loss: 0.7498 G_loss: 2.002\n",
      "Iter: 29100 D loss: 0.7866 G_loss: 2.117\n",
      "Iter: 29200 D loss: 0.7393 G_loss: 1.958\n",
      "Iter: 29300 D loss: 0.6572 G_loss: 1.778\n",
      "Iter: 29400 D loss: 0.9556 G_loss: 1.919\n",
      "Iter: 29500 D loss: 0.7466 G_loss: 2.004\n",
      "Iter: 29600 D loss: 0.8207 G_loss: 1.925\n",
      "Iter: 29700 D loss: 0.7212 G_loss: 1.767\n",
      "Iter: 29800 D loss: 0.9331 G_loss: 1.798\n",
      "Iter: 29900 D loss: 0.7068 G_loss: 1.969\n",
      "Iter: 30000 D loss: 0.6617 G_loss: 2.233\n",
      "Iter: 30100 D loss: 0.7397 G_loss: 2.023\n",
      "Iter: 30200 D loss: 0.8368 G_loss: 2.009\n",
      "Iter: 30300 D loss: 0.7391 G_loss: 1.763\n",
      "Iter: 30400 D loss: 0.6648 G_loss: 1.859\n",
      "Iter: 30500 D loss: 0.7714 G_loss: 1.869\n",
      "Iter: 30600 D loss: 0.8225 G_loss: 1.732\n",
      "Iter: 30700 D loss: 0.8121 G_loss: 2.174\n",
      "Iter: 30800 D loss: 0.7535 G_loss: 1.944\n",
      "Iter: 30900 D loss: 0.8086 G_loss: 2.202\n",
      "Iter: 31000 D loss: 0.6848 G_loss: 2.04\n",
      "Iter: 31100 D loss: 0.7716 G_loss: 1.797\n",
      "Iter: 31200 D loss: 0.8439 G_loss: 2.062\n",
      "Iter: 31300 D loss: 0.7163 G_loss: 1.697\n",
      "Iter: 31400 D loss: 0.727 G_loss: 1.997\n",
      "Iter: 31500 D loss: 0.6583 G_loss: 1.676\n",
      "Iter: 31600 D loss: 0.7392 G_loss: 2.062\n",
      "Iter: 31700 D loss: 0.7283 G_loss: 1.879\n",
      "Iter: 31800 D loss: 0.7439 G_loss: 2.025\n",
      "Iter: 31900 D loss: 0.8909 G_loss: 1.673\n",
      "Iter: 32000 D loss: 0.7234 G_loss: 1.877\n",
      "Iter: 32100 D loss: 0.6268 G_loss: 1.8\n",
      "Iter: 32200 D loss: 0.9071 G_loss: 2.015\n",
      "Iter: 32300 D loss: 0.7992 G_loss: 1.928\n",
      "Iter: 32400 D loss: 0.8006 G_loss: 1.841\n",
      "Iter: 32500 D loss: 0.7439 G_loss: 1.799\n",
      "Iter: 32600 D loss: 0.8402 G_loss: 1.758\n",
      "Iter: 32700 D loss: 0.7757 G_loss: 1.99\n",
      "Iter: 32800 D loss: 0.7905 G_loss: 1.818\n",
      "Iter: 32900 D loss: 0.7784 G_loss: 2.135\n",
      "Iter: 33000 D loss: 0.7136 G_loss: 1.824\n",
      "Iter: 33100 D loss: 0.6015 G_loss: 2.036\n",
      "Iter: 33200 D loss: 0.7751 G_loss: 2.005\n",
      "Iter: 33300 D loss: 0.8435 G_loss: 1.771\n",
      "Iter: 33400 D loss: 0.8079 G_loss: 1.958\n",
      "Iter: 33500 D loss: 0.9154 G_loss: 1.941\n",
      "Iter: 33600 D loss: 0.7703 G_loss: 2.082\n",
      "Iter: 33700 D loss: 0.9412 G_loss: 1.724\n",
      "Iter: 33800 D loss: 0.7411 G_loss: 2.153\n",
      "Iter: 33900 D loss: 0.7928 G_loss: 1.991\n",
      "Iter: 34000 D loss: 0.6982 G_loss: 1.885\n",
      "Iter: 34100 D loss: 0.8406 G_loss: 2.011\n",
      "Iter: 34200 D loss: 0.7325 G_loss: 1.889\n",
      "Iter: 34300 D loss: 0.6973 G_loss: 1.961\n",
      "Iter: 34400 D loss: 0.7642 G_loss: 1.889\n",
      "Iter: 34500 D loss: 0.7357 G_loss: 1.742\n",
      "Iter: 34600 D loss: 0.6694 G_loss: 1.754\n",
      "Iter: 34700 D loss: 0.8807 G_loss: 1.844\n",
      "Iter: 34800 D loss: 0.6392 G_loss: 2.028\n",
      "Iter: 34900 D loss: 0.8841 G_loss: 2.127\n",
      "Iter: 35000 D loss: 0.639 G_loss: 2.118\n",
      "Iter: 35100 D loss: 0.7926 G_loss: 2.079\n",
      "Iter: 35200 D loss: 0.7661 G_loss: 1.918\n",
      "Iter: 35300 D loss: 0.6344 G_loss: 1.857\n",
      "Iter: 35400 D loss: 0.7629 G_loss: 2.065\n",
      "Iter: 35500 D loss: 0.7835 G_loss: 2.124\n",
      "Iter: 35600 D loss: 0.9228 G_loss: 1.902\n",
      "Iter: 35700 D loss: 0.6593 G_loss: 2.08\n",
      "Iter: 35800 D loss: 0.7559 G_loss: 1.934\n",
      "Iter: 35900 D loss: 0.6402 G_loss: 2.43\n",
      "Iter: 36000 D loss: 0.7552 G_loss: 1.967\n",
      "Iter: 36100 D loss: 0.7422 G_loss: 2.185\n",
      "Iter: 36200 D loss: 0.7794 G_loss: 1.894\n",
      "Iter: 36300 D loss: 0.6782 G_loss: 1.736\n",
      "Iter: 36400 D loss: 0.6927 G_loss: 1.924\n",
      "Iter: 36500 D loss: 0.6299 G_loss: 1.769\n",
      "Iter: 36600 D loss: 0.8312 G_loss: 1.887\n",
      "Iter: 36700 D loss: 0.5486 G_loss: 2.261\n",
      "Iter: 36800 D loss: 0.8317 G_loss: 1.964\n",
      "Iter: 36900 D loss: 0.6804 G_loss: 1.949\n",
      "Iter: 37000 D loss: 0.7251 G_loss: 2.188\n",
      "Iter: 37100 D loss: 0.7232 G_loss: 2.217\n",
      "Iter: 37200 D loss: 0.7056 G_loss: 2.039\n",
      "Iter: 37300 D loss: 0.6856 G_loss: 2.158\n",
      "Iter: 37400 D loss: 0.7727 G_loss: 1.926\n",
      "Iter: 37500 D loss: 0.7516 G_loss: 1.996\n",
      "Iter: 37600 D loss: 0.7437 G_loss: 1.736\n",
      "Iter: 37700 D loss: 0.6874 G_loss: 1.945\n",
      "Iter: 37800 D loss: 0.7296 G_loss: 2.053\n",
      "Iter: 37900 D loss: 0.7025 G_loss: 1.839\n",
      "Iter: 38000 D loss: 0.7644 G_loss: 1.889\n",
      "Iter: 38100 D loss: 0.8239 G_loss: 2.114\n",
      "Iter: 38200 D loss: 0.6045 G_loss: 1.968\n",
      "Iter: 38300 D loss: 0.7417 G_loss: 2.071\n",
      "Iter: 38400 D loss: 0.7042 G_loss: 1.96\n",
      "Iter: 38500 D loss: 0.7503 G_loss: 1.848\n",
      "Iter: 38600 D loss: 0.6879 G_loss: 2.076\n",
      "Iter: 38700 D loss: 0.8822 G_loss: 1.979\n",
      "Iter: 38800 D loss: 0.7344 G_loss: 1.907\n",
      "Iter: 38900 D loss: 0.8775 G_loss: 1.901\n",
      "Iter: 39000 D loss: 0.8706 G_loss: 1.988\n",
      "Iter: 39100 D loss: 0.7862 G_loss: 1.693\n",
      "Iter: 39200 D loss: 0.8734 G_loss: 2.126\n",
      "Iter: 39300 D loss: 0.7963 G_loss: 1.874\n",
      "Iter: 39400 D loss: 0.8878 G_loss: 2.007\n",
      "Iter: 39500 D loss: 0.8719 G_loss: 2.053\n",
      "Iter: 39600 D loss: 0.7712 G_loss: 1.928\n",
      "Iter: 39700 D loss: 0.8557 G_loss: 2.064\n",
      "Iter: 39800 D loss: 0.7156 G_loss: 1.82\n",
      "Iter: 39900 D loss: 0.8157 G_loss: 1.806\n",
      "Iter: 40000 D loss: 0.741 G_loss: 1.877\n",
      "Iter: 40100 D loss: 0.7742 G_loss: 2.077\n",
      "Iter: 40200 D loss: 0.7558 G_loss: 1.75\n",
      "Iter: 40300 D loss: 0.7791 G_loss: 1.983\n",
      "Iter: 40400 D loss: 0.6927 G_loss: 2.075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 40500 D loss: 0.7319 G_loss: 2.221\n",
      "Iter: 40600 D loss: 0.733 G_loss: 2.174\n",
      "Iter: 40700 D loss: 0.9048 G_loss: 1.967\n",
      "Iter: 40800 D loss: 0.733 G_loss: 1.988\n",
      "Iter: 40900 D loss: 0.7015 G_loss: 1.969\n",
      "Iter: 41000 D loss: 0.756 G_loss: 2.02\n",
      "Iter: 41100 D loss: 0.821 G_loss: 1.945\n",
      "Iter: 41200 D loss: 0.7889 G_loss: 1.853\n",
      "Iter: 41300 D loss: 0.7453 G_loss: 2.048\n",
      "Iter: 41400 D loss: 0.802 G_loss: 1.8\n",
      "Iter: 41500 D loss: 0.7953 G_loss: 1.904\n",
      "Iter: 41600 D loss: 0.8211 G_loss: 2.076\n",
      "Iter: 41700 D loss: 0.722 G_loss: 2.17\n",
      "Iter: 41800 D loss: 0.8333 G_loss: 2.002\n",
      "Iter: 41900 D loss: 0.808 G_loss: 2.045\n",
      "Iter: 42000 D loss: 0.8284 G_loss: 1.954\n",
      "Iter: 42100 D loss: 0.8924 G_loss: 2.019\n",
      "Iter: 42200 D loss: 0.7023 G_loss: 1.992\n",
      "Iter: 42300 D loss: 0.7849 G_loss: 1.956\n",
      "Iter: 42400 D loss: 0.7037 G_loss: 1.938\n",
      "Iter: 42500 D loss: 0.747 G_loss: 1.932\n",
      "Iter: 42600 D loss: 0.7167 G_loss: 2.125\n",
      "Iter: 42700 D loss: 0.6287 G_loss: 1.891\n",
      "Iter: 42800 D loss: 0.6966 G_loss: 2.021\n",
      "Iter: 42900 D loss: 0.6768 G_loss: 2.288\n",
      "Iter: 43000 D loss: 0.6906 G_loss: 2.118\n",
      "Iter: 43100 D loss: 0.7105 G_loss: 2.174\n",
      "Iter: 43200 D loss: 0.7363 G_loss: 1.698\n",
      "Iter: 43300 D loss: 0.6796 G_loss: 1.997\n",
      "Iter: 43400 D loss: 0.6372 G_loss: 1.999\n",
      "Iter: 43500 D loss: 0.7897 G_loss: 1.647\n",
      "Iter: 43600 D loss: 0.7214 G_loss: 2.269\n",
      "Iter: 43700 D loss: 0.7865 G_loss: 1.959\n",
      "Iter: 43800 D loss: 0.6802 G_loss: 1.899\n",
      "Iter: 43900 D loss: 0.8832 G_loss: 2.003\n",
      "Iter: 44000 D loss: 0.8266 G_loss: 1.935\n",
      "Iter: 44100 D loss: 0.6991 G_loss: 2.082\n",
      "Iter: 44200 D loss: 0.7103 G_loss: 2.088\n",
      "Iter: 44300 D loss: 0.8056 G_loss: 2.07\n",
      "Iter: 44400 D loss: 0.7923 G_loss: 2.179\n",
      "Iter: 44500 D loss: 0.6954 G_loss: 2.41\n",
      "Iter: 44600 D loss: 0.6172 G_loss: 2.022\n",
      "Iter: 44700 D loss: 0.6721 G_loss: 2.174\n",
      "Iter: 44800 D loss: 0.6684 G_loss: 2.093\n",
      "Iter: 44900 D loss: 0.8017 G_loss: 2.023\n",
      "Iter: 45000 D loss: 0.6699 G_loss: 1.815\n",
      "Iter: 45100 D loss: 0.7833 G_loss: 2.215\n",
      "Iter: 45200 D loss: 0.8774 G_loss: 2.066\n",
      "Iter: 45300 D loss: 0.7336 G_loss: 1.937\n",
      "Iter: 45400 D loss: 0.753 G_loss: 2.224\n",
      "Iter: 45500 D loss: 0.6843 G_loss: 2.405\n",
      "Iter: 45600 D loss: 0.8012 G_loss: 2.047\n",
      "Iter: 45700 D loss: 0.7607 G_loss: 2.013\n",
      "Iter: 45800 D loss: 0.6626 G_loss: 2.22\n",
      "Iter: 45900 D loss: 0.7926 G_loss: 2.089\n",
      "Iter: 46000 D loss: 0.6295 G_loss: 2.218\n",
      "Iter: 46100 D loss: 0.7739 G_loss: 1.939\n",
      "Iter: 46200 D loss: 0.68 G_loss: 1.834\n",
      "Iter: 46300 D loss: 0.7914 G_loss: 1.961\n",
      "Iter: 46400 D loss: 0.7816 G_loss: 1.838\n",
      "Iter: 46500 D loss: 0.7256 G_loss: 2.021\n",
      "Iter: 46600 D loss: 0.6742 G_loss: 2.066\n",
      "Iter: 46700 D loss: 0.7518 G_loss: 1.935\n",
      "Iter: 46800 D loss: 0.7746 G_loss: 1.97\n",
      "Iter: 46900 D loss: 0.6994 G_loss: 2.105\n",
      "Iter: 47000 D loss: 0.7111 G_loss: 2.277\n",
      "Iter: 47100 D loss: 0.7568 G_loss: 2.104\n",
      "Iter: 47200 D loss: 0.7593 G_loss: 1.87\n",
      "Iter: 47300 D loss: 0.8287 G_loss: 1.89\n",
      "Iter: 47400 D loss: 0.723 G_loss: 2.024\n",
      "Iter: 47500 D loss: 0.6698 G_loss: 2.018\n",
      "Iter: 47600 D loss: 0.7738 G_loss: 2.005\n",
      "Iter: 47700 D loss: 0.7532 G_loss: 2.18\n",
      "Iter: 47800 D loss: 0.802 G_loss: 2.072\n",
      "Iter: 47900 D loss: 0.6664 G_loss: 2.019\n",
      "Iter: 48000 D loss: 0.7032 G_loss: 1.795\n",
      "Iter: 48100 D loss: 0.7328 G_loss: 2.157\n",
      "Iter: 48200 D loss: 0.8794 G_loss: 2.154\n",
      "Iter: 48300 D loss: 0.6788 G_loss: 2.15\n",
      "Iter: 48400 D loss: 0.6459 G_loss: 2.422\n",
      "Iter: 48500 D loss: 0.7259 G_loss: 2.112\n",
      "Iter: 48600 D loss: 0.725 G_loss: 1.989\n",
      "Iter: 48700 D loss: 0.7287 G_loss: 2.153\n",
      "Iter: 48800 D loss: 0.8165 G_loss: 2.221\n",
      "Iter: 48900 D loss: 0.8283 G_loss: 1.867\n",
      "Iter: 49000 D loss: 0.7484 G_loss: 2.049\n",
      "Iter: 49100 D loss: 0.6592 G_loss: 2.063\n",
      "Iter: 49200 D loss: 0.7925 G_loss: 1.878\n",
      "Iter: 49300 D loss: 0.6432 G_loss: 1.965\n",
      "Iter: 49400 D loss: 0.8985 G_loss: 1.83\n",
      "Iter: 49500 D loss: 0.738 G_loss: 1.968\n",
      "Iter: 49600 D loss: 0.7225 G_loss: 1.822\n",
      "Iter: 49700 D loss: 0.8321 G_loss: 1.933\n",
      "Iter: 49800 D loss: 0.6466 G_loss: 1.953\n",
      "Iter: 49900 D loss: 0.7797 G_loss: 1.833\n",
      "Iter: 50000 D loss: 0.671 G_loss: 2.013\n",
      "Iter: 50100 D loss: 0.6985 G_loss: 1.858\n",
      "Iter: 50200 D loss: 0.8704 G_loss: 2.235\n",
      "Iter: 50300 D loss: 0.7171 G_loss: 1.866\n",
      "Iter: 50400 D loss: 0.6774 G_loss: 1.954\n",
      "Iter: 50500 D loss: 0.8196 G_loss: 2.176\n",
      "Iter: 50600 D loss: 0.7519 G_loss: 1.868\n",
      "Iter: 50700 D loss: 0.8684 G_loss: 2.187\n",
      "Iter: 50800 D loss: 0.6225 G_loss: 2.05\n",
      "Iter: 50900 D loss: 0.7033 G_loss: 2.029\n",
      "Iter: 51000 D loss: 0.7087 G_loss: 1.974\n",
      "Iter: 51100 D loss: 0.7427 G_loss: 2.233\n",
      "Iter: 51200 D loss: 0.7977 G_loss: 2.048\n",
      "Iter: 51300 D loss: 0.7516 G_loss: 2.198\n",
      "Iter: 51400 D loss: 0.828 G_loss: 2.112\n",
      "Iter: 51500 D loss: 0.7087 G_loss: 1.988\n",
      "Iter: 51600 D loss: 0.7158 G_loss: 2.069\n",
      "Iter: 51700 D loss: 0.6276 G_loss: 1.995\n",
      "Iter: 51800 D loss: 0.6212 G_loss: 2.2\n",
      "Iter: 51900 D loss: 0.691 G_loss: 1.965\n",
      "Iter: 52000 D loss: 0.6896 G_loss: 2.055\n",
      "Iter: 52100 D loss: 0.6571 G_loss: 1.758\n",
      "Iter: 52200 D loss: 0.7686 G_loss: 2.295\n",
      "Iter: 52300 D loss: 0.6656 G_loss: 2.34\n",
      "Iter: 52400 D loss: 0.7152 G_loss: 1.884\n",
      "Iter: 52500 D loss: 0.7196 G_loss: 2.022\n",
      "Iter: 52600 D loss: 0.7284 G_loss: 2.132\n",
      "Iter: 52700 D loss: 0.6135 G_loss: 1.922\n",
      "Iter: 52800 D loss: 0.7314 G_loss: 1.986\n",
      "Iter: 52900 D loss: 0.6508 G_loss: 2.021\n",
      "Iter: 53000 D loss: 0.721 G_loss: 2.052\n",
      "Iter: 53100 D loss: 0.6733 G_loss: 2.162\n",
      "Iter: 53200 D loss: 0.8803 G_loss: 2.102\n",
      "Iter: 53300 D loss: 0.7544 G_loss: 2.137\n",
      "Iter: 53400 D loss: 0.6661 G_loss: 2.204\n",
      "Iter: 53500 D loss: 0.6915 G_loss: 1.745\n",
      "Iter: 53600 D loss: 0.7234 G_loss: 1.923\n",
      "Iter: 53700 D loss: 0.7133 G_loss: 2.163\n",
      "Iter: 53800 D loss: 0.7259 G_loss: 1.889\n",
      "Iter: 53900 D loss: 0.7086 G_loss: 2.342\n",
      "Iter: 54000 D loss: 0.8684 G_loss: 1.897\n",
      "Iter: 54100 D loss: 0.747 G_loss: 2.143\n",
      "Iter: 54200 D loss: 0.6942 G_loss: 2.137\n",
      "Iter: 54300 D loss: 0.7246 G_loss: 2.188\n",
      "Iter: 54400 D loss: 0.6286 G_loss: 2.295\n",
      "Iter: 54500 D loss: 0.7969 G_loss: 2.022\n",
      "Iter: 54600 D loss: 0.7535 G_loss: 2.17\n",
      "Iter: 54700 D loss: 0.5783 G_loss: 2.396\n",
      "Iter: 54800 D loss: 0.7075 G_loss: 2.119\n",
      "Iter: 54900 D loss: 0.7082 G_loss: 1.99\n",
      "Iter: 55000 D loss: 0.7938 G_loss: 1.881\n",
      "Iter: 55100 D loss: 0.7805 G_loss: 2.023\n",
      "Iter: 55200 D loss: 0.7148 G_loss: 2.06\n",
      "Iter: 55300 D loss: 0.7179 G_loss: 2.007\n",
      "Iter: 55400 D loss: 0.6757 G_loss: 2.172\n",
      "Iter: 55500 D loss: 0.5724 G_loss: 2.12\n",
      "Iter: 55600 D loss: 0.7171 G_loss: 1.878\n",
      "Iter: 55700 D loss: 0.6361 G_loss: 2.237\n",
      "Iter: 55800 D loss: 0.7412 G_loss: 2.399\n",
      "Iter: 55900 D loss: 0.6883 G_loss: 2.241\n",
      "Iter: 56000 D loss: 0.6143 G_loss: 2.269\n",
      "Iter: 56100 D loss: 0.7748 G_loss: 2.094\n",
      "Iter: 56200 D loss: 0.7591 G_loss: 1.978\n",
      "Iter: 56300 D loss: 0.8393 G_loss: 2.087\n",
      "Iter: 56400 D loss: 0.7302 G_loss: 2.083\n",
      "Iter: 56500 D loss: 0.7076 G_loss: 2.066\n",
      "Iter: 56600 D loss: 0.6696 G_loss: 2.164\n",
      "Iter: 56700 D loss: 0.6691 G_loss: 1.946\n",
      "Iter: 56800 D loss: 0.7188 G_loss: 2.037\n",
      "Iter: 56900 D loss: 0.642 G_loss: 2.156\n",
      "Iter: 57000 D loss: 0.7153 G_loss: 2.228\n",
      "Iter: 57100 D loss: 0.678 G_loss: 2.038\n",
      "Iter: 57200 D loss: 0.6776 G_loss: 2.368\n",
      "Iter: 57300 D loss: 0.7306 G_loss: 2.063\n",
      "Iter: 57400 D loss: 0.6937 G_loss: 2.021\n",
      "Iter: 57500 D loss: 0.6603 G_loss: 1.939\n",
      "Iter: 57600 D loss: 0.7112 G_loss: 2.105\n",
      "Iter: 57700 D loss: 0.7206 G_loss: 2.455\n",
      "Iter: 57800 D loss: 0.6105 G_loss: 2.007\n",
      "Iter: 57900 D loss: 0.7244 G_loss: 2.23\n",
      "Iter: 58000 D loss: 0.7195 G_loss: 2.101\n",
      "Iter: 58100 D loss: 0.7565 G_loss: 2.284\n",
      "Iter: 58200 D loss: 0.639 G_loss: 2.199\n",
      "Iter: 58300 D loss: 0.6619 G_loss: 2.349\n",
      "Iter: 58400 D loss: 0.7742 G_loss: 2.064\n",
      "Iter: 58500 D loss: 0.7737 G_loss: 1.989\n",
      "Iter: 58600 D loss: 0.7266 G_loss: 2.278\n",
      "Iter: 58700 D loss: 0.7992 G_loss: 2.094\n",
      "Iter: 58800 D loss: 0.7475 G_loss: 2.182\n",
      "Iter: 58900 D loss: 0.6568 G_loss: 2.374\n",
      "Iter: 59000 D loss: 0.7047 G_loss: 1.929\n",
      "Iter: 59100 D loss: 0.6509 G_loss: 2.168\n",
      "Iter: 59200 D loss: 0.541 G_loss: 2.208\n",
      "Iter: 59300 D loss: 0.704 G_loss: 2.368\n",
      "Iter: 59400 D loss: 0.7276 G_loss: 2.078\n",
      "Iter: 59500 D loss: 0.5837 G_loss: 2.343\n",
      "Iter: 59600 D loss: 0.7723 G_loss: 2.286\n",
      "Iter: 59700 D loss: 0.6739 G_loss: 2.335\n",
      "Iter: 59800 D loss: 0.7313 G_loss: 2.053\n",
      "Iter: 59900 D loss: 0.6622 G_loss: 2.48\n",
      "Iter: 60000 D loss: 0.6721 G_loss: 2.237\n",
      "Iter: 60100 D loss: 0.773 G_loss: 1.897\n",
      "Iter: 60200 D loss: 0.6548 G_loss: 2.208\n",
      "Iter: 60300 D loss: 0.5827 G_loss: 2.344\n",
      "Iter: 60400 D loss: 0.7281 G_loss: 2.321\n",
      "Iter: 60500 D loss: 0.5685 G_loss: 2.295\n",
      "Iter: 60600 D loss: 0.5649 G_loss: 2.447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 60700 D loss: 0.6725 G_loss: 2.451\n",
      "Iter: 60800 D loss: 0.7517 G_loss: 2.092\n",
      "Iter: 60900 D loss: 0.71 G_loss: 1.918\n",
      "Iter: 61000 D loss: 0.5811 G_loss: 2.332\n",
      "Iter: 61100 D loss: 0.6033 G_loss: 2.156\n",
      "Iter: 61200 D loss: 0.5755 G_loss: 2.387\n",
      "Iter: 61300 D loss: 0.6076 G_loss: 2.023\n",
      "Iter: 61400 D loss: 0.7276 G_loss: 2.301\n",
      "Iter: 61500 D loss: 0.6081 G_loss: 2.191\n",
      "Iter: 61600 D loss: 0.7032 G_loss: 2.358\n",
      "Iter: 61700 D loss: 0.6749 G_loss: 2.325\n",
      "Iter: 61800 D loss: 0.6433 G_loss: 2.353\n",
      "Iter: 61900 D loss: 0.5758 G_loss: 2.051\n",
      "Iter: 62000 D loss: 0.7596 G_loss: 2.006\n",
      "Iter: 62100 D loss: 0.5082 G_loss: 2.54\n",
      "Iter: 62200 D loss: 0.5943 G_loss: 2.14\n",
      "Iter: 62300 D loss: 0.6515 G_loss: 2.279\n",
      "Iter: 62400 D loss: 0.5787 G_loss: 2.34\n",
      "Iter: 62500 D loss: 0.6606 G_loss: 2.274\n",
      "Iter: 62600 D loss: 0.6284 G_loss: 2.124\n",
      "Iter: 62700 D loss: 0.6721 G_loss: 2.156\n",
      "Iter: 62800 D loss: 0.5953 G_loss: 2.027\n",
      "Iter: 62900 D loss: 0.6638 G_loss: 2.217\n",
      "Iter: 63000 D loss: 0.5885 G_loss: 2.154\n",
      "Iter: 63100 D loss: 0.6814 G_loss: 2.191\n",
      "Iter: 63200 D loss: 0.6813 G_loss: 1.992\n",
      "Iter: 63300 D loss: 0.6759 G_loss: 2.262\n",
      "Iter: 63400 D loss: 0.6635 G_loss: 2.117\n",
      "Iter: 63500 D loss: 0.7294 G_loss: 2.235\n",
      "Iter: 63600 D loss: 0.6837 G_loss: 2.155\n",
      "Iter: 63700 D loss: 0.6618 G_loss: 2.067\n",
      "Iter: 63800 D loss: 0.6277 G_loss: 2.091\n",
      "Iter: 63900 D loss: 0.7197 G_loss: 1.914\n",
      "Iter: 64000 D loss: 0.6649 G_loss: 2.299\n",
      "Iter: 64100 D loss: 0.5621 G_loss: 2.449\n",
      "Iter: 64200 D loss: 0.629 G_loss: 2.062\n",
      "Iter: 64300 D loss: 0.5765 G_loss: 2.356\n",
      "Iter: 64400 D loss: 0.6294 G_loss: 2.157\n",
      "Iter: 64500 D loss: 0.5831 G_loss: 2.174\n",
      "Iter: 64600 D loss: 0.6747 G_loss: 2.025\n",
      "Iter: 64700 D loss: 0.6189 G_loss: 2.279\n",
      "Iter: 64800 D loss: 0.5737 G_loss: 2.356\n",
      "Iter: 64900 D loss: 0.6842 G_loss: 2.12\n",
      "Iter: 65000 D loss: 0.7378 G_loss: 2.418\n",
      "Iter: 65100 D loss: 0.4958 G_loss: 2.312\n",
      "Iter: 65200 D loss: 0.6615 G_loss: 2.277\n",
      "Iter: 65300 D loss: 0.597 G_loss: 2.05\n",
      "Iter: 65400 D loss: 0.6789 G_loss: 2.345\n",
      "Iter: 65500 D loss: 0.6998 G_loss: 1.975\n",
      "Iter: 65600 D loss: 0.5966 G_loss: 2.276\n",
      "Iter: 65700 D loss: 0.609 G_loss: 2.465\n",
      "Iter: 65800 D loss: 0.6396 G_loss: 2.474\n",
      "Iter: 65900 D loss: 0.655 G_loss: 2.396\n",
      "Iter: 66000 D loss: 0.6414 G_loss: 2.173\n",
      "Iter: 66100 D loss: 0.7167 G_loss: 2.044\n",
      "Iter: 66200 D loss: 0.5476 G_loss: 2.169\n",
      "Iter: 66300 D loss: 0.6976 G_loss: 2.31\n",
      "Iter: 66400 D loss: 0.6371 G_loss: 2.304\n",
      "Iter: 66500 D loss: 0.706 G_loss: 2.526\n",
      "Iter: 66600 D loss: 0.6872 G_loss: 2.339\n",
      "Iter: 66700 D loss: 0.568 G_loss: 2.269\n",
      "Iter: 66800 D loss: 0.6076 G_loss: 2.259\n",
      "Iter: 66900 D loss: 0.8506 G_loss: 2.237\n",
      "Iter: 67000 D loss: 0.5664 G_loss: 2.235\n",
      "Iter: 67100 D loss: 0.5242 G_loss: 2.42\n",
      "Iter: 67200 D loss: 0.7568 G_loss: 2.26\n",
      "Iter: 67300 D loss: 0.6162 G_loss: 2.16\n",
      "Iter: 67400 D loss: 0.6091 G_loss: 2.36\n",
      "Iter: 67500 D loss: 0.5139 G_loss: 2.353\n",
      "Iter: 67600 D loss: 0.5537 G_loss: 2.294\n",
      "Iter: 67700 D loss: 0.6822 G_loss: 2.423\n",
      "Iter: 67800 D loss: 0.6335 G_loss: 2.397\n",
      "Iter: 67900 D loss: 0.782 G_loss: 2.117\n",
      "Iter: 68000 D loss: 0.5893 G_loss: 2.375\n",
      "Iter: 68100 D loss: 0.6235 G_loss: 2.286\n",
      "Iter: 68200 D loss: 0.6364 G_loss: 2.075\n",
      "Iter: 68300 D loss: 0.6634 G_loss: 2.217\n",
      "Iter: 68400 D loss: 0.6847 G_loss: 2.379\n",
      "Iter: 68500 D loss: 0.5525 G_loss: 2.202\n",
      "Iter: 68600 D loss: 0.618 G_loss: 2.231\n",
      "Iter: 68700 D loss: 0.5964 G_loss: 2.397\n",
      "Iter: 68800 D loss: 0.6869 G_loss: 2.073\n",
      "Iter: 68900 D loss: 0.5741 G_loss: 2.508\n",
      "Iter: 69000 D loss: 0.595 G_loss: 2.257\n",
      "Iter: 69100 D loss: 0.5564 G_loss: 2.328\n",
      "Iter: 69200 D loss: 0.525 G_loss: 2.409\n",
      "Iter: 69300 D loss: 0.7464 G_loss: 2.323\n",
      "Iter: 69400 D loss: 0.5964 G_loss: 2.254\n",
      "Iter: 69500 D loss: 0.6992 G_loss: 2.095\n",
      "Iter: 69600 D loss: 0.6593 G_loss: 2.313\n",
      "Iter: 69700 D loss: 0.552 G_loss: 2.478\n",
      "Iter: 69800 D loss: 0.6395 G_loss: 2.261\n",
      "Iter: 69900 D loss: 0.6599 G_loss: 2.361\n",
      "Iter: 70000 D loss: 0.7303 G_loss: 2.315\n",
      "Iter: 70100 D loss: 0.5809 G_loss: 2.444\n",
      "Iter: 70200 D loss: 0.5192 G_loss: 2.51\n",
      "Iter: 70300 D loss: 0.5928 G_loss: 2.29\n",
      "Iter: 70400 D loss: 0.6997 G_loss: 2.121\n",
      "Iter: 70500 D loss: 0.6007 G_loss: 2.469\n",
      "Iter: 70600 D loss: 0.6124 G_loss: 2.26\n",
      "Iter: 70700 D loss: 0.5787 G_loss: 2.315\n",
      "Iter: 70800 D loss: 0.6413 G_loss: 2.501\n",
      "Iter: 70900 D loss: 0.581 G_loss: 2.196\n",
      "Iter: 71000 D loss: 0.5829 G_loss: 2.571\n",
      "Iter: 71100 D loss: 0.7565 G_loss: 2.333\n",
      "Iter: 71200 D loss: 0.5529 G_loss: 2.089\n",
      "Iter: 71300 D loss: 0.6199 G_loss: 2.15\n",
      "Iter: 71400 D loss: 0.6441 G_loss: 2.398\n",
      "Iter: 71500 D loss: 0.6065 G_loss: 2.558\n",
      "Iter: 71600 D loss: 0.6188 G_loss: 2.394\n",
      "Iter: 71700 D loss: 0.5421 G_loss: 2.386\n",
      "Iter: 71800 D loss: 0.6566 G_loss: 2.184\n",
      "Iter: 71900 D loss: 0.7246 G_loss: 2.422\n",
      "Iter: 72000 D loss: 0.5128 G_loss: 2.646\n",
      "Iter: 72100 D loss: 0.6611 G_loss: 2.479\n",
      "Iter: 72200 D loss: 0.6192 G_loss: 2.489\n",
      "Iter: 72300 D loss: 0.5997 G_loss: 2.421\n",
      "Iter: 72400 D loss: 0.659 G_loss: 2.337\n",
      "Iter: 72500 D loss: 0.6849 G_loss: 2.625\n",
      "Iter: 72600 D loss: 0.6085 G_loss: 2.291\n",
      "Iter: 72700 D loss: 0.6015 G_loss: 2.358\n",
      "Iter: 72800 D loss: 0.6216 G_loss: 2.546\n",
      "Iter: 72900 D loss: 0.6379 G_loss: 2.426\n",
      "Iter: 73000 D loss: 0.691 G_loss: 2.252\n",
      "Iter: 73100 D loss: 0.5761 G_loss: 2.311\n",
      "Iter: 73200 D loss: 0.5588 G_loss: 2.494\n",
      "Iter: 73300 D loss: 0.6494 G_loss: 2.236\n",
      "Iter: 73400 D loss: 0.5886 G_loss: 2.704\n",
      "Iter: 73500 D loss: 0.4695 G_loss: 2.401\n",
      "Iter: 73600 D loss: 0.6059 G_loss: 2.235\n",
      "Iter: 73700 D loss: 0.5655 G_loss: 2.718\n",
      "Iter: 73800 D loss: 0.6055 G_loss: 2.186\n",
      "Iter: 73900 D loss: 0.6493 G_loss: 2.193\n",
      "Iter: 74000 D loss: 0.6052 G_loss: 2.15\n",
      "Iter: 74100 D loss: 0.6515 G_loss: 2.09\n",
      "Iter: 74200 D loss: 0.6111 G_loss: 2.386\n",
      "Iter: 74300 D loss: 0.5018 G_loss: 2.549\n",
      "Iter: 74400 D loss: 0.6519 G_loss: 2.193\n",
      "Iter: 74500 D loss: 0.5009 G_loss: 2.305\n",
      "Iter: 74600 D loss: 0.7446 G_loss: 2.209\n",
      "Iter: 74700 D loss: 0.5593 G_loss: 2.369\n",
      "Iter: 74800 D loss: 0.6358 G_loss: 2.449\n",
      "Iter: 74900 D loss: 0.5055 G_loss: 2.538\n",
      "Iter: 75000 D loss: 0.5908 G_loss: 2.288\n",
      "Iter: 75100 D loss: 0.5309 G_loss: 2.248\n",
      "Iter: 75200 D loss: 0.6565 G_loss: 2.425\n",
      "Iter: 75300 D loss: 0.5624 G_loss: 2.327\n",
      "Iter: 75400 D loss: 0.5774 G_loss: 2.266\n",
      "Iter: 75500 D loss: 0.5959 G_loss: 2.679\n",
      "Iter: 75600 D loss: 0.565 G_loss: 2.274\n",
      "Iter: 75700 D loss: 0.5258 G_loss: 2.725\n",
      "Iter: 75800 D loss: 0.5512 G_loss: 2.201\n",
      "Iter: 75900 D loss: 0.6748 G_loss: 2.47\n",
      "Iter: 76000 D loss: 0.546 G_loss: 2.182\n",
      "Iter: 76100 D loss: 0.5537 G_loss: 2.573\n",
      "Iter: 76200 D loss: 0.5576 G_loss: 2.197\n",
      "Iter: 76300 D loss: 0.6005 G_loss: 2.31\n",
      "Iter: 76400 D loss: 0.6582 G_loss: 2.508\n",
      "Iter: 76500 D loss: 0.5682 G_loss: 2.451\n",
      "Iter: 76600 D loss: 0.6263 G_loss: 2.361\n",
      "Iter: 76700 D loss: 0.6107 G_loss: 2.381\n",
      "Iter: 76800 D loss: 0.7335 G_loss: 2.24\n",
      "Iter: 76900 D loss: 0.558 G_loss: 2.542\n",
      "Iter: 77000 D loss: 0.5465 G_loss: 2.815\n",
      "Iter: 77100 D loss: 0.5646 G_loss: 2.758\n",
      "Iter: 77200 D loss: 0.5189 G_loss: 2.407\n",
      "Iter: 77300 D loss: 0.5228 G_loss: 2.443\n",
      "Iter: 77400 D loss: 0.6389 G_loss: 2.53\n",
      "Iter: 77500 D loss: 0.5825 G_loss: 2.655\n",
      "Iter: 77600 D loss: 0.5939 G_loss: 2.476\n",
      "Iter: 77700 D loss: 0.5457 G_loss: 2.642\n",
      "Iter: 77800 D loss: 0.5979 G_loss: 2.449\n",
      "Iter: 77900 D loss: 0.6031 G_loss: 2.502\n",
      "Iter: 78000 D loss: 0.6801 G_loss: 2.593\n",
      "Iter: 78100 D loss: 0.5999 G_loss: 2.29\n",
      "Iter: 78200 D loss: 0.6438 G_loss: 2.298\n",
      "Iter: 78300 D loss: 0.5914 G_loss: 2.678\n",
      "Iter: 78400 D loss: 0.5402 G_loss: 2.548\n",
      "Iter: 78500 D loss: 0.5849 G_loss: 2.72\n",
      "Iter: 78600 D loss: 0.7393 G_loss: 2.586\n",
      "Iter: 78700 D loss: 0.5874 G_loss: 2.252\n",
      "Iter: 78800 D loss: 0.5322 G_loss: 2.468\n",
      "Iter: 78900 D loss: 0.5474 G_loss: 2.288\n",
      "Iter: 79000 D loss: 0.5482 G_loss: 2.729\n",
      "Iter: 79100 D loss: 0.5232 G_loss: 2.373\n",
      "Iter: 79200 D loss: 0.5894 G_loss: 2.864\n",
      "Iter: 79300 D loss: 0.6023 G_loss: 2.478\n",
      "Iter: 79400 D loss: 0.5363 G_loss: 2.438\n",
      "Iter: 79500 D loss: 0.5352 G_loss: 2.664\n",
      "Iter: 79600 D loss: 0.58 G_loss: 2.412\n",
      "Iter: 79700 D loss: 0.4895 G_loss: 2.369\n",
      "Iter: 79800 D loss: 0.6263 G_loss: 2.488\n",
      "Iter: 79900 D loss: 0.6626 G_loss: 2.42\n",
      "Iter: 80000 D loss: 0.6091 G_loss: 2.283\n",
      "Iter: 80100 D loss: 0.5658 G_loss: 2.517\n",
      "Iter: 80200 D loss: 0.6084 G_loss: 2.444\n",
      "Iter: 80300 D loss: 0.5871 G_loss: 2.525\n",
      "Iter: 80400 D loss: 0.5667 G_loss: 2.347\n",
      "Iter: 80500 D loss: 0.5216 G_loss: 2.721\n",
      "Iter: 80600 D loss: 0.5905 G_loss: 2.469\n",
      "Iter: 80700 D loss: 0.553 G_loss: 2.591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 80800 D loss: 0.7482 G_loss: 2.621\n",
      "Iter: 80900 D loss: 0.5799 G_loss: 2.689\n",
      "Iter: 81000 D loss: 0.6268 G_loss: 2.521\n",
      "Iter: 81100 D loss: 0.531 G_loss: 2.191\n",
      "Iter: 81200 D loss: 0.5896 G_loss: 2.655\n",
      "Iter: 81300 D loss: 0.5448 G_loss: 2.359\n",
      "Iter: 81400 D loss: 0.5559 G_loss: 2.549\n",
      "Iter: 81500 D loss: 0.5732 G_loss: 2.089\n",
      "Iter: 81600 D loss: 0.5246 G_loss: 2.824\n",
      "Iter: 81700 D loss: 0.6573 G_loss: 2.766\n",
      "Iter: 81800 D loss: 0.5004 G_loss: 2.397\n",
      "Iter: 81900 D loss: 0.4493 G_loss: 2.574\n",
      "Iter: 82000 D loss: 0.5257 G_loss: 2.336\n",
      "Iter: 82100 D loss: 0.5204 G_loss: 2.346\n",
      "Iter: 82200 D loss: 0.5772 G_loss: 2.417\n",
      "Iter: 82300 D loss: 0.6483 G_loss: 2.724\n",
      "Iter: 82400 D loss: 0.5943 G_loss: 2.559\n",
      "Iter: 82500 D loss: 0.4879 G_loss: 2.586\n",
      "Iter: 82600 D loss: 0.5521 G_loss: 2.616\n",
      "Iter: 82700 D loss: 0.4569 G_loss: 2.535\n",
      "Iter: 82800 D loss: 0.517 G_loss: 2.668\n",
      "Iter: 82900 D loss: 0.5905 G_loss: 2.636\n",
      "Iter: 83000 D loss: 0.624 G_loss: 2.698\n",
      "Iter: 83100 D loss: 0.5227 G_loss: 2.55\n",
      "Iter: 83200 D loss: 0.5231 G_loss: 2.496\n",
      "Iter: 83300 D loss: 0.6139 G_loss: 2.388\n",
      "Iter: 83400 D loss: 0.4694 G_loss: 2.445\n",
      "Iter: 83500 D loss: 0.5565 G_loss: 2.384\n",
      "Iter: 83600 D loss: 0.5776 G_loss: 2.31\n",
      "Iter: 83700 D loss: 0.5503 G_loss: 2.379\n",
      "Iter: 83800 D loss: 0.5444 G_loss: 2.465\n",
      "Iter: 83900 D loss: 0.6373 G_loss: 2.566\n",
      "Iter: 84000 D loss: 0.517 G_loss: 2.587\n",
      "Iter: 84100 D loss: 0.502 G_loss: 2.571\n",
      "Iter: 84200 D loss: 0.6529 G_loss: 2.493\n",
      "Iter: 84300 D loss: 0.5591 G_loss: 2.51\n",
      "Iter: 84400 D loss: 0.4731 G_loss: 2.772\n",
      "Iter: 84500 D loss: 0.5405 G_loss: 2.569\n",
      "Iter: 84600 D loss: 0.5651 G_loss: 2.635\n",
      "Iter: 84700 D loss: 0.5638 G_loss: 2.7\n",
      "Iter: 84800 D loss: 0.6757 G_loss: 2.745\n",
      "Iter: 84900 D loss: 0.5274 G_loss: 2.854\n",
      "Iter: 85000 D loss: 0.497 G_loss: 2.631\n",
      "Iter: 85100 D loss: 0.6388 G_loss: 2.527\n",
      "Iter: 85200 D loss: 0.6937 G_loss: 2.36\n",
      "Iter: 85300 D loss: 0.5854 G_loss: 2.303\n",
      "Iter: 85400 D loss: 0.6667 G_loss: 2.415\n",
      "Iter: 85500 D loss: 0.5873 G_loss: 2.544\n",
      "Iter: 85600 D loss: 0.5311 G_loss: 2.362\n",
      "Iter: 85700 D loss: 0.5752 G_loss: 2.314\n",
      "Iter: 85800 D loss: 0.5024 G_loss: 2.329\n",
      "Iter: 85900 D loss: 0.5738 G_loss: 2.587\n",
      "Iter: 86000 D loss: 0.4301 G_loss: 2.69\n",
      "Iter: 86100 D loss: 0.4759 G_loss: 2.49\n",
      "Iter: 86200 D loss: 0.5453 G_loss: 2.439\n",
      "Iter: 86300 D loss: 0.4428 G_loss: 2.378\n",
      "Iter: 86400 D loss: 0.5545 G_loss: 2.458\n",
      "Iter: 86500 D loss: 0.4709 G_loss: 2.646\n",
      "Iter: 86600 D loss: 0.5369 G_loss: 2.162\n",
      "Iter: 86700 D loss: 0.6976 G_loss: 2.528\n",
      "Iter: 86800 D loss: 0.4514 G_loss: 2.442\n",
      "Iter: 86900 D loss: 0.5773 G_loss: 2.533\n",
      "Iter: 87000 D loss: 0.5054 G_loss: 2.561\n",
      "Iter: 87100 D loss: 0.494 G_loss: 2.466\n",
      "Iter: 87200 D loss: 0.4874 G_loss: 2.631\n",
      "Iter: 87300 D loss: 0.6057 G_loss: 2.882\n",
      "Iter: 87400 D loss: 0.5416 G_loss: 2.556\n",
      "Iter: 87500 D loss: 0.5076 G_loss: 2.426\n",
      "Iter: 87600 D loss: 0.6895 G_loss: 2.59\n",
      "Iter: 87700 D loss: 0.6384 G_loss: 2.791\n",
      "Iter: 87800 D loss: 0.4905 G_loss: 2.374\n",
      "Iter: 87900 D loss: 0.5798 G_loss: 2.18\n",
      "Iter: 88000 D loss: 0.5058 G_loss: 3.01\n",
      "Iter: 88100 D loss: 0.6931 G_loss: 2.335\n",
      "Iter: 88200 D loss: 0.6259 G_loss: 2.519\n",
      "Iter: 88300 D loss: 0.6375 G_loss: 2.603\n",
      "Iter: 88400 D loss: 0.463 G_loss: 2.382\n",
      "Iter: 88500 D loss: 0.6498 G_loss: 2.508\n",
      "Iter: 88600 D loss: 0.4903 G_loss: 2.434\n",
      "Iter: 88700 D loss: 0.5376 G_loss: 2.428\n",
      "Iter: 88800 D loss: 0.5957 G_loss: 2.648\n",
      "Iter: 88900 D loss: 0.5015 G_loss: 2.449\n",
      "Iter: 89000 D loss: 0.5627 G_loss: 2.495\n",
      "Iter: 89100 D loss: 0.7066 G_loss: 2.568\n",
      "Iter: 89200 D loss: 0.4785 G_loss: 2.6\n",
      "Iter: 89300 D loss: 0.5913 G_loss: 2.404\n",
      "Iter: 89400 D loss: 0.6078 G_loss: 2.673\n",
      "Iter: 89500 D loss: 0.5212 G_loss: 2.255\n",
      "Iter: 89600 D loss: 0.5612 G_loss: 2.505\n",
      "Iter: 89700 D loss: 0.5767 G_loss: 2.539\n",
      "Iter: 89800 D loss: 0.5087 G_loss: 2.543\n",
      "Iter: 89900 D loss: 0.5325 G_loss: 2.765\n",
      "Iter: 90000 D loss: 0.4807 G_loss: 2.604\n",
      "Iter: 90100 D loss: 0.6928 G_loss: 2.777\n",
      "Iter: 90200 D loss: 0.5112 G_loss: 2.383\n",
      "Iter: 90300 D loss: 0.5305 G_loss: 2.329\n",
      "Iter: 90400 D loss: 0.6837 G_loss: 2.554\n",
      "Iter: 90500 D loss: 0.4961 G_loss: 2.568\n",
      "Iter: 90600 D loss: 0.5252 G_loss: 2.56\n",
      "Iter: 90700 D loss: 0.5454 G_loss: 2.645\n",
      "Iter: 90800 D loss: 0.5431 G_loss: 2.748\n",
      "Iter: 90900 D loss: 0.5505 G_loss: 2.741\n",
      "Iter: 91000 D loss: 0.4621 G_loss: 2.709\n",
      "Iter: 91100 D loss: 0.5716 G_loss: 2.3\n",
      "Iter: 91200 D loss: 0.4838 G_loss: 2.375\n",
      "Iter: 91300 D loss: 0.563 G_loss: 2.669\n",
      "Iter: 91400 D loss: 0.573 G_loss: 2.598\n",
      "Iter: 91500 D loss: 0.6137 G_loss: 2.863\n",
      "Iter: 91600 D loss: 0.6003 G_loss: 2.717\n",
      "Iter: 91700 D loss: 0.5156 G_loss: 2.703\n",
      "Iter: 91800 D loss: 0.5459 G_loss: 2.742\n",
      "Iter: 91900 D loss: 0.5363 G_loss: 2.592\n",
      "Iter: 92000 D loss: 0.4685 G_loss: 2.564\n",
      "Iter: 92100 D loss: 0.4688 G_loss: 2.708\n",
      "Iter: 92200 D loss: 0.6248 G_loss: 2.317\n",
      "Iter: 92300 D loss: 0.4224 G_loss: 2.651\n",
      "Iter: 92400 D loss: 0.5207 G_loss: 2.43\n",
      "Iter: 92500 D loss: 0.5117 G_loss: 2.731\n",
      "Iter: 92600 D loss: 0.5375 G_loss: 2.642\n",
      "Iter: 92700 D loss: 0.4374 G_loss: 2.303\n",
      "Iter: 92800 D loss: 0.4899 G_loss: 2.818\n",
      "Iter: 92900 D loss: 0.5472 G_loss: 2.638\n",
      "Iter: 93000 D loss: 0.5079 G_loss: 2.552\n",
      "Iter: 93100 D loss: 0.5597 G_loss: 2.31\n",
      "Iter: 93200 D loss: 0.6198 G_loss: 2.403\n",
      "Iter: 93300 D loss: 0.4476 G_loss: 2.767\n",
      "Iter: 93400 D loss: 0.4883 G_loss: 2.758\n",
      "Iter: 93500 D loss: 0.4375 G_loss: 2.63\n",
      "Iter: 93600 D loss: 0.4311 G_loss: 2.577\n",
      "Iter: 93700 D loss: 0.4585 G_loss: 2.41\n",
      "Iter: 93800 D loss: 0.5636 G_loss: 2.937\n",
      "Iter: 93900 D loss: 0.5743 G_loss: 2.567\n",
      "Iter: 94000 D loss: 0.4221 G_loss: 2.416\n",
      "Iter: 94100 D loss: 0.5488 G_loss: 3.05\n",
      "Iter: 94200 D loss: 0.5656 G_loss: 2.689\n",
      "Iter: 94300 D loss: 0.5288 G_loss: 2.688\n",
      "Iter: 94400 D loss: 0.4748 G_loss: 2.799\n",
      "Iter: 94500 D loss: 0.5187 G_loss: 2.459\n",
      "Iter: 94600 D loss: 0.454 G_loss: 2.572\n",
      "Iter: 94700 D loss: 0.582 G_loss: 2.512\n",
      "Iter: 94800 D loss: 0.5412 G_loss: 2.712\n",
      "Iter: 94900 D loss: 0.5695 G_loss: 2.654\n",
      "Iter: 95000 D loss: 0.5379 G_loss: 2.467\n",
      "Iter: 95100 D loss: 0.494 G_loss: 2.528\n",
      "Iter: 95200 D loss: 0.5245 G_loss: 2.465\n",
      "Iter: 95300 D loss: 0.5152 G_loss: 2.665\n",
      "Iter: 95400 D loss: 0.5506 G_loss: 2.651\n",
      "Iter: 95500 D loss: 0.5408 G_loss: 2.48\n",
      "Iter: 95600 D loss: 0.5091 G_loss: 2.674\n",
      "Iter: 95700 D loss: 0.4928 G_loss: 2.769\n",
      "Iter: 95800 D loss: 0.6571 G_loss: 2.298\n",
      "Iter: 95900 D loss: 0.6298 G_loss: 2.66\n",
      "Iter: 96000 D loss: 0.4411 G_loss: 2.929\n",
      "Iter: 96100 D loss: 0.5124 G_loss: 2.424\n",
      "Iter: 96200 D loss: 0.6251 G_loss: 2.467\n",
      "Iter: 96300 D loss: 0.4483 G_loss: 2.284\n",
      "Iter: 96400 D loss: 0.501 G_loss: 2.722\n",
      "Iter: 96500 D loss: 0.4814 G_loss: 2.468\n",
      "Iter: 96600 D loss: 0.5751 G_loss: 2.647\n",
      "Iter: 96700 D loss: 0.5086 G_loss: 2.308\n",
      "Iter: 96800 D loss: 0.4959 G_loss: 2.686\n",
      "Iter: 96900 D loss: 0.6352 G_loss: 2.532\n",
      "Iter: 97000 D loss: 0.4949 G_loss: 2.72\n",
      "Iter: 97100 D loss: 0.5548 G_loss: 2.67\n",
      "Iter: 97200 D loss: 0.5301 G_loss: 2.789\n",
      "Iter: 97300 D loss: 0.505 G_loss: 2.707\n",
      "Iter: 97400 D loss: 0.4875 G_loss: 2.714\n",
      "Iter: 97500 D loss: 0.5051 G_loss: 2.557\n",
      "Iter: 97600 D loss: 0.6194 G_loss: 2.574\n",
      "Iter: 97700 D loss: 0.5979 G_loss: 2.64\n",
      "Iter: 97800 D loss: 0.4831 G_loss: 2.434\n",
      "Iter: 97900 D loss: 0.5484 G_loss: 2.68\n",
      "Iter: 98000 D loss: 0.4961 G_loss: 2.68\n",
      "Iter: 98100 D loss: 0.5347 G_loss: 2.812\n",
      "Iter: 98200 D loss: 0.5144 G_loss: 2.649\n",
      "Iter: 98300 D loss: 0.553 G_loss: 2.631\n",
      "Iter: 98400 D loss: 0.5556 G_loss: 2.557\n",
      "Iter: 98500 D loss: 0.5233 G_loss: 2.576\n",
      "Iter: 98600 D loss: 0.4789 G_loss: 2.608\n",
      "Iter: 98700 D loss: 0.6351 G_loss: 2.446\n",
      "Iter: 98800 D loss: 0.6554 G_loss: 2.543\n",
      "Iter: 98900 D loss: 0.5202 G_loss: 2.307\n",
      "Iter: 99000 D loss: 0.5883 G_loss: 3.114\n",
      "Iter: 99100 D loss: 0.5 G_loss: 2.624\n",
      "Iter: 99200 D loss: 0.5332 G_loss: 2.294\n",
      "Iter: 99300 D loss: 0.6092 G_loss: 2.959\n",
      "Iter: 99400 D loss: 0.5967 G_loss: 2.729\n",
      "Iter: 99500 D loss: 0.5029 G_loss: 2.782\n",
      "Iter: 99600 D loss: 0.5029 G_loss: 2.615\n",
      "Iter: 99700 D loss: 0.5419 G_loss: 2.247\n",
      "Iter: 99800 D loss: 0.5293 G_loss: 2.61\n",
      "Iter: 99900 D loss: 0.5307 G_loss: 2.625\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "GLoss = []\n",
    "DLoss = []\n",
    "\n",
    "if not os.path.exists('out/'):\n",
    "    os.makedirs('out/')\n",
    "\n",
    "for it in range(100000):\n",
    "    if it % 100 == 0:\n",
    "        samples = sess.run(G_sample, feed_dict={Z: sample_Z(25, Z_dim)})\n",
    "\n",
    "        fig = plot(samples)\n",
    "        plt.savefig('out/{}.png'.format(str(it).zfill(3)), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "    X_mb, _ = data.train.next_batch(batch_size)\n",
    "\n",
    "    _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, Z: sample_Z(batch_size, Z_dim)})\n",
    "    _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={Z: sample_Z(batch_size, Z_dim)})\n",
    "    GLoss.append(G_loss_curr)\n",
    "    DLoss.append(D_loss_curr)\n",
    "\n",
    "    if it % 100 == 0:\n",
    "        print('Iter: {} D loss: {:.4} G_loss: {:.4}'.format(it,D_loss_curr, G_loss_curr))\n",
    "        \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Loss')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3Xd4VFX6wPHvSSOU0ENHAkgHCRCKgBRBQLAv2HthrfwEC7i6iqyuiqjIiiAWRNYVFAUVUJAqKAIJRXpHCCWEkt6T8/vj3GQmySQZksxMmHk/z5Nn7tx2zs1N7nvvuacorTVCCCF8l5+nMyCEEMKzJBAIIYSPk0AghBA+TgKBEEL4OAkEQgjh4yQQCCGEj5NAIIQQPk4CgRBC+DgJBEII4eMCPJ0BZ9StW1eHhYV5OhtCCHFJiYqKOqu1Di1pvUsiEISFhREZGenpbAghxCVFKfWXM+tJ0ZAQQvg4CQRCCOHjJBAIIYSPuyTeEQghipeZmUl0dDRpaWmezorwgODgYJo0aUJgYGCptndZIFBKfQZcB5zRWne05tUG5gNhwFHgVq31BVflQQhfER0dTUhICGFhYSilPJ0d4UZaa86dO0d0dDTNmzcv1T5cWTT0OTCswLwJwEqtdStgpfVdCFFGaWlp1KlTR4KAD1JKUadOnTI9DbosEGitfwXOF5h9IzDHmp4D3OSq9IXwNRIEfFdZz727XxbX11qfArA+67k19awM+GMmyPCcQgiRp8LWGlJKjVZKRSqlImNjY8tnp5+PgJ/Hw+Kny2d/Qog8/v7+hIeH06FDBzp37sy7775LTk4OAJGRkYwZM6bMacycOZMvvvjiorbp3bt3qdP7/PPPOXnyZKm3B5g4cSJTpkwp0z5czd21hmKUUg211qeUUg2BM0WtqLWeBcwCiIiIKJ9b+OhN5nP/snLZnRDCpnLlymzbtg2AM2fOcOeddxIfH8+rr75KREQEERERZdp/VlYWjz766EVv9/vvv5c6zc8//5yOHTvSqFEjp7fJzs7G39+/1Gl6grufCH4A7rOm7wO+d3P6hhQNCeFS9erVY9asWXzwwQdorVmzZg3XXXcdAGvXriU8PJzw8HC6dOlCYmIiAJMnT6ZTp0507tyZCRNMPZIBAwbwj3/8g/79+/P+++/nu7seMGAAY8eOpV+/frRr147Nmzdzyy230KpVK1566aW8vFSrVg2ANWvWMGDAAEaOHEnbtm2566670Na1YNKkSXTv3p2OHTsyevRotNYsWLCAyMhI7rrrLsLDw0lNTWXlypV06dKFTp068eCDD5Keng6YbnAmTZpE3759+eabb5z6Hb377rt07NiRjh07MnXqVACSk5MZMWIEnTt3pmPHjsyfPx+ACRMm0L59e6644gqeffbZMp0bR1xZffQrYABQVykVDbwCvAl8rZR6CDgGjHJV+sWTQCC816s/7mL3yYRy3Wf7RtV55foOF7VNixYtyMnJ4cyZ/A/+U6ZMYfr06fTp04ekpCSCg4P56aefWLRoERs3bqRKlSqcP2+rZxIXF8fatWsBU8xiLygoiF9//ZX333+fG2+8kaioKGrXrk3Lli0ZO3YsderUybf+1q1b2bVrF40aNaJPnz789ttv9O3blyeffJKXX34ZgHvuuYfFixczcuRIPvjgA6ZMmUJERARpaWncf//9rFy5ktatW3PvvfcyY8YMnn7aFDUHBwezfv16p343UVFRzJ49m40bN6K1pmfPnvTv35/Dhw/TqFEjlixZAkB8fDznz59n4cKF7N27F6UUcXFxzp8EJ7my1tAdWuuGWutArXUTrfWnWutzWutBWutW1mfBWkXuIU8EQriFdvC/1qdPH8aNG8e0adOIi4sjICCAFStW8MADD1ClShUAateunbf+bbfdVuT+b7jhBgA6depEhw4daNiwIZUqVaJFixYcP3680Po9evSgSZMm+Pn5ER4eztGjRwFYvXo1PXv2pFOnTqxatYpdu3YV2nbfvn00b96c1q1bA3Dffffx66+/OpXPgtavX8/NN99M1apVqVatGrfccgvr1q2jU6dOrFixgvHjx7Nu3Tpq1KhB9erVCQ4O5uGHH+a7777L+x2VJx9tWSyBQHivi71zd5XDhw/j7+9PvXr12LNnT978CRMmMGLECJYuXUqvXr1YsWIFWusiq0BWrVq1yDQqVaoEgJ+fX9507vesrKwi1wfzcjsrK4u0tDQef/xxIiMjadq0KRMnTnRYJ99RUHM2n87uq3Xr1kRFRbF06VJeeOEFhgwZwssvv8ymTZtYuXIl8+bN44MPPmDVqlVOp+WMCltryKXkiUAIl4qNjeXRRx/lySefLHSBP3ToEJ06dWL8+PFERESwd+9ehgwZwmeffUZKSgpAvqIhV8u96NetW5ekpCQWLFiQtywkJCTvHUbbtm05evQoBw8eBGDu3Ln079+/VGn269ePRYsWkZKSQnJyMgsXLuSqq67i5MmTVKlShbvvvptnn32WLVu2kJSURHx8PMOHD2fq1Kl5L+TLkzwRCCHKRWpqKuHh4WRmZhIQEMA999zDuHHjCq03depUVq9ejb+/P+3bt+faa6+lUqVKbNu2jYiICIKCghg+fDj//ve/3ZLvmjVr8sgjj9CpUyfCwsLo3r173rL777+fRx99lMqVK7NhwwZmz57NqFGjyMrKonv37k7XYnrttdfyXgiD6RLk/vvvp0ePHgA8/PDDdOnShWXLlvHcc8/h5+dHYGAgM2bMIDExkRtvvJG0tDS01rz33nvl+wsAVEmPOxVBRESELpeBaSbWMJ+Va8P4I2XfnxAVxJ49e2jXrp2nsyE8yNHfgFIqSmtdYr1d3ywakicCIYTI45uB4BJ4ChJCCHeRQCCEED7ONwOBFA0JIUQe3wwE8kQghBB5fDMQyBOBEELk8c1AIE8EQpS7mJgY7rzzTlq0aEG3bt248sorWbhwocfys2bNmjL1PJq7j9zO8ryZbwaCzGRP50AIr6K15qabbqJfv34cPnyYqKgo5s2bR3R0tEvTddSNRK7SBILi9ufNfDMQCCHK1apVqwgKCsrX0rZZs2Y89dRTgOmj/7nnnqN79+5cccUVfPTRR0DxXUNHRUXRv39/unXrxtChQzl16hRQuGvqH3/8kZ49e9KlSxcGDx5MTEwMR48eZebMmbz33nuEh4ezbt06/vrrLwYNGsQVV1zBoEGDOHbsGGBaD48bN46BAwcyfvx4p463qO6oHXUX/c0339CxY0c6d+5Mv379yuG3Xf58tIsJIbzYTxPg9I7y3WeDTnDtm0Uu3rVrF127di1y+aeffkqNGjXYvHkz6enp9OnThyFDhgCOu4bu2bMnTz31FN9//z2hoaHMnz+fF198kc8++wzI3zX1hQsX+OOPP1BK8cknnzB58mTeeecdHn30UapVq5Z3Qb7++uu59957ue+++/jss88YM2YMixYtAmD//v2sWLHCqQFliuqO+t5773XYXfSkSZNYtmwZjRs3dkkX0uVBAoEQotw98cQTrF+/nqCgIDZv3szy5cv5888/8zp0i4+P58CBAwQFBeV1DQ3kdQ1ds2ZNdu7cyTXXXAOYJ4qGDRvm7d++y+fo6Ghuu+02Tp06RUZGBs2bN3eYpw0bNvDdd98BZsyB559/Pm/ZqFGjnB5VzFF31NOnT+fJJ5/M6y56xIgRee8W+vTpw/3338+tt97KLbfc4lQa7iaBQAhvU8ydu6t06NCBb7/9Nu/79OnTOXv2bN7wlFpr/vOf/zB06NB8261Zs8Zh19Baazp06MCGDRscpmff5fNTTz3FuHHjuOGGG1izZk2hwWuKYt8ranl0IR0QEOCwu+iZM2eyceNGlixZQnh4ONu2bSs0YI6nyTsCIUSZXX311aSlpTFjxoy8ebldSgMMHTqUGTNmkJmZCZiimOTkoitttGnThtjY2LxAkJmZ6XCwGDBPF40bNwZgzpw5efPtu5AGM4j9vHnzAPjyyy/p27fvxR4mUHR31EV1F33o0CF69uzJpEmTqFu3rsMBczxNngiEEGWmlGLRokWMHTuWyZMnExoaStWqVXnrrbcA083y0aNH6dq1K1prQkND88rnHQkKCmLBggWMGTOG+Ph4srKyePrpp+nQofCgOxMnTmTUqFE0btyYXr16ceSI6Vn4+uuvZ+TIkXz//ff85z//Ydq0aTz44IO8/fbbhIaGMnv2bKeObeXKlXlFV2Be/jrqjvr8+fMOu4t+7rnnOHDgAFprBg0aROfOnZ3+vbqLb3ZDDTAxvuz7E6KCkG6ohXRDLYQQotQkEAghhI+TQCCEl7gUinmFa5T13EsgEMILBAcHc+7cOQkGPkhrzblz5wgODi71PqTWkBBeoEmTJkRHRxMbG+vprAgPCA4Ozlez6WJJIBDCCwQGBhbZolaIkkjRkBBC+DgJBEII4eN8MxA06+PpHAghRIXhm4FA+eZhCyGEI755RZRAIIQQeXzziujnXL/jQgjhCzwSCJRSY5VSu5RSO5VSXymlSt8SolQZ8M34J4QQjrj9iqiUagyMASK01h0Bf+B2t2aidku3JieEEBWZp26NA4DKSqkAoApw0q2phzRwa3JCCFGRuT0QaK1PAFOAY8ApIF5rvdytmZCiISGEyOOJoqFawI1Ac6ARUFUpdbeD9UYrpSKVUpHl3n+KBAIhhMjjiSviYOCI1jpWa50JfAf0LriS1nqW1jpCax0RGhpavjmQQCCEEHk8cUU8BvRSSlVRSilgELDHrTmQ6qNCCJHHE+8INgILgC3ADisPs9ybC+Xe5IQQogLzSDfUWutXgFc8kbaVA88lLYQQFYxvFpave9fTORBCiArDNwNB8hlP50AIISoM3wwEQggh8kggEEIIHyeBQAghfJwEAiGE8HESCIQQwsdJIBBCCB8ngUAIIXycbwWCqvU8nQMhhKhwfCsQXNbT0zkQQogKx7cCwZ4fPZ0DIYSocHwrEAghhChEAoEQQvg4CQRCCOHjJBAIIYSPk0AghBA+TgKBEEL4OAkEQgjh4yQQCCGEj5NAIIQQPk4CgRBC+DgJBEII4eN8NxAknobUOE/nQgghPC7A0xnwmHfamM+J8Z7NhxBCeJjvPhHkSk/ydA6EEMKjJBDobE/nQAghPMp3AsHS5x3PV77zKxBCCEe8+yqYlQHJ58z0po+KWEm5LTtCCFEReXcg+PoeeLtF8esoCQRCCN/m3YFg/8+ezoEQQlR4HgkESqmaSqkFSqm9Sqk9SqkrPZEPIYQQnmtH8D7ws9Z6pFIqCKjioXwIIYTPc3sgUEpVB/oB9wNorTOADJcmmpNT9DKtXZq0EEJUdJ4oGmoBxAKzlVJblVKfKKWqFlxJKTVaKRWplIqMjY0tW4qp54teliENyoQQvs0TgSAA6ArM0Fp3AZKBCQVX0lrP0lpHaK0jQkNDy5ZicXf9Z3aXbd9CCHGJ80QgiAaitdYbre8LMIHBdXQxRUOJMS5NWgghKjq3BwKt9WnguFLK6vWNQYBrb8uL60Yi27WvJ4QQoqLzVK2hp4AvrRpDh4EHXJpaZqpLdy+EEJcyjwQCrfU2IMJtCRb3Qji4utuyIYQQFZF3tyzOlZ1ZzLIs9+VDCCEqIB8JBMW8Bzh3IP/3Fa/CxBquzY8QQlQgvhEIlH/Ryw6tzv99/bvmc8cCOLLOdXkSQogKwjcCwV+/Fb0sK83x/G8fgjnXQU42LB4H54+4Jm9CCOFhvhEINs0qetnpP4vf9kQURH4K3z5cvnkSQogKwqlAoJRqqZSqZE0PUEqNUUrVdG3WylF59Cck4xYIIbyUs08E3wLZSqnLgU+B5sD/XJar8pZ0uuz7kM7phBBeytlAkKO1zgJuBqZqrccCDV2XrYpEngSEEN7N2UCQqZS6A7gPWGzNC3RNlioqeSIQQngnZwPBA8CVwOta6yNKqebAf12XrQok2eoC+0SUZ/MhhBAu4lQXE1rr3cAYAKVULSBEa/2mKzNWYRRX9VQIIbyAs7WG1iilqiulagPbMYPKvOvarFUQGz7wdA6EEMKlnC0aqqG1TgBuAWZrrbsBg12XrQqquD6LhBDiEuVsIAhQSjUEbsX2svjS8+Dysm2fkVw++RBCiArE2UAwCVgGHNJab1ZKtQAOlLBNxVOtjENeHlpVPvkQQogKxKlAoLX+Rmt9hdb6Mev7Ya3131ybNRcICC7b9ju+MQ3LDq2GnGKGvxRCiEuIsy+LmyilFiqlziilYpRS3yqlmrg6c2VXoDGYf6Wy7U7nwN7FMPcm2DizbPsSQogKwtmiodnAD0AjoDHwozXv0hIQ5Hj+uUP5P4sSswvm322m4/4qv3wJIYQHORsIQrXWs7XWWdbP50AZC9zdoGBHcf5FBIJd35nP9ITi9xd/3H7npc6WEEJUJM4GgrNKqbuVUv7Wz93AOVdmzCX8SugVY8FDzu9L+cHuHyD1QtnyJIQQHuZsIHgQU3X0NHAKGInpduLS4lfU4Vp39+dLKBqyd2AZfH0PvBUGq/9d1pwJIYTHOFtr6JjW+gatdajWup7W+iZM4zLvcGLLxY9TfO6gbXrtW+WbHyGEcKOyjFA2rtxy4TJOluPvW+LabAghRAVWlkAgb0uFEMILlCUQVPwO+t05vOTCx4peFh8NPz4N2Vnuy48QQjip2ECglEpUSiU4+EnEtCm4dLQZ7tr9by9m5M7vn4So2XBkrWvzIIQQpVDseARa6xB3ZcTlajYzn34BkOPuO3Pr4cmdTyhCCOGkshQNXQLsLrx+/uazWn3PZEUIISooLw8EdtLizGfCCdelkRgDf21w3f6FEMIFnBqq0isof9en8U5r8zkx3vVpCSFEOfHYE4HVVcVWpZR7BroZMMEtyRRLV/yKVkII3+PJoqH/A/a4NAX7l7PybkAIIRzySCCwxjIYAXzivkStQ23QyW1JFs6D1BoSQlQ8nnoimAo8D7hvmK/ci/AwN/QLlHzWDHS/6WPIyXZ9ekIIUQZuf1mslLoOOKO1jlJKDShmvdHAaIDLLrus/DJQ1Q3DKLzdEq6ZBL+87Pq0hBCijDzxRNAHuEEpdRSYB1ytlPpvwZW01rO01hFa64jQ0NJevB0UxbireObPr81n4mlIs2oR/TEDYna7J30hhHCS2wOB1voFrXUTrXUYcDuwSmt9t9sykOamqp0xO83nuilwcquZPrAcZlzpnvSFEMJJvtOgLJcrG5QJIcQlyKMNyrTWa4A1LktAaukIIUSJfO+JoCLYVkxPpUII4Wa+FwgqQuveRcWMXSCEEG7me4FACCFEPl4eCBy9I6gATwQAWRmezoEQQgBeHwgcsC8aGr3GU7mAjCTPpS2EEHZ8LxDYPxE06uJ4lZrl2JK5yGxUkCcTIUTpzL8bvnnA+fWzMszY5vHRjpcnn4OoOeWTt4vk3YEgK7XwvBpOXORvK9TQufz9Pg3OH4bF42z9EU2sYX7SElyfvhCibPb8CLu+c379g7+Ysc2XPud4+Xvt4ccx8Ovb5ZO/i+DdgcCR6o2KX97pVmjY2fX5+G0q/O82iPwUTm6DtXYn/9xB16cvhChf/wqFL24q/fZZaeZz1Wvlk5+L4HuBoKSXxb3cWLXz7H7rcx+stjv57uoGQwhflZlauHh279LSt/HJTIPsDDi8Ov/8c4fgP91gy1yYd6eZpwt0upx8FlLOly7dcuJ7gaCksvnGXd2TD3sF2xUcWuX+PAjhzeJPmCdvgIRT8HoD2DjTlMvnFsXOu6Pw/+KOBXB6p+17dmbhGn9p8bDm37bvp3eYz4xkmHO9ecL/4Unb8uMbzafW5uftljC5edmPsQx8Z8ziXIFVLn6bXo/DHx+Wf16K8vs0GPIv96UnREV09Dc4tQ2ufMLx8nOHID0RGoUXvY+DK+C/f7N9v28xJMWY6V0L4ecJ4BcIL5/Nv986Lc30tw+Zz9xxyN9oWvjd45sF3jseWQd+AfBhL8d5Sr1gAsDMvrbOKQs6fxiW/xNGzQF/11+mfe+JoGqdi99m2Bvln4+S/P6B+9MUoiJYO9lcwD8fDsv+UXh5VjpkpMB/usKs/oWXx0fDV3fC2QP5gwDAnOtsF/fcO/OcTJNmruX/LLzPw2uttB1UQCloy5yig0CuV2sWHQQApnWBvYvNvtzA954ILhXLX4TuD0NgsKdzIkTpxUdDpRAIruH8Nqtfz/89KwMCgsz03Fvg0Mrit3+vg/nct6R0ae5bAl/fC4Mn2uZ9cYPz+4rd6/y6JVkyDro/VH77K4LvPRE4a+Rnjue3GOi+PLxe331pCeGsfT/BwWIuxhNrwJJnzfR7HWB6L/My9Ncptnd0Gcm2wZtybfzItp29zR+bp4Df3i86CBzfDJNbmmKX8rD7e3NX7iMkENw0wzY97E3bdMcCj5RV6prP5le5Pk/2srMg6YwZ/1iIiuCr2+G/tzhelmyVtW/+2PztAiSeNC9DV/0Ljq4z85Y+B989Asc32bb96XmzXUFH1sGGD4oe+vXYRvh0MKScNVWyvY0b2hX5ZtHQsDehvvX4GH6n+XFk4Iu2mgbNesOeH6B2S/fkMZdSpvXiX+uheX8Ibe3e9IUoydkD8EGE6bIldzQ+yF8lOld6ovnc9qX5/PQaCGkEY4spL9//E6TFFb38syG26dxyf29yIhJaXu3SJHwzEDjbVqD/847nhzQydznukBST/6WWEKWVkWJevg6eCJVr2uZv+x8knoKrnoEVr0KLAdDCwUvYX16BU9tt32f0MS88Q6xGmismwuE1tuXr3yu8j3kObroST8Kk2sXn/diG4pd7s7MHXB4IpGioNNzZ1mDqFRIARPnYMgeiZsNbzfLPX/QYrJxkpte/a3sxmpNjLv4Zyeb7b1PzN5jKrfWSe1NkHwRE+VGuv0z7RiDo839l38cVt5rPhp2hXnvb/Lptyr7v4uQLAsq0iPxhjMdbIgo3SHeyh9rcluj7foLYffmXZaaZd0yn/jR15nNlpEDCSVM7xpHkc7Bxhrn4/7uRdJLoSW4Yctc3iobqdyr7Ptpdb2tUYq9OS9NFhDusfw/qtjJ3dmcPwH0/gH+ge9IW7rVrIXxzP4xe67jBVFY6BFSCE1Hw8dUw6nOzPtj+ThNPwzvWjUpEgSqInw2F03/mnxd3zDb9dov8y16tifAU1wcC734iaDPCfHYa6dl8lJcdX9vqOx/7Hd53Q+d44uKdP2KqUNrXiClJbg+0YJ4Eci/q9mXyuTbOgtfqwby7TBCA/NU5D62GPYttQQBM54b2CgYBgKnlcMMkyp+fv+uTcHkKnla/Y/k/WvkHle/+SivhhLmA7F1iLjyvNXB84RCFnd5hfmcxu8t/3wdXmM/tXxW9TnqiSX/Fq/DHDPOy9JeXTRBYYNfHfabVknXtZLP+2rfhJ6sb472LbettnWubnnsTzL+rfI5FeJ6SQFAOXPBYZd/3iSc6qbM3uYWtJkZWKnzUzzwpZKR4Nl8VUU4O7F9uyrt3LTTz9i6Bo+utoLCrbPte944pr8/tXbLgP/CBX0wr2YxkeKOJmbf+XVvZ/W/vwxuN4cBy2zY/jzfb5D4JOqqSKbxb3VYuT8I33hGUtyC7juv6PgN/bSi52burOKpffeEonDtgG1chJ8c8FbnhpdNFS4o1nWpVrlXyuu+0M20+BjnoC6agtHjTEKdmU9u8758wA4OMmmMLlAd/geQzZvrIOlv7EjB37ZVC8u83Jwe2fgE/Pg1PbjbdCcTsMi1aN840HZbV72jW3fyx+RnwgqmS+WUpiyhfCy3ddsI7+Emnc2XkhpoOfn5w9YuuT+diaW1qi2Slw6RaZlg9e59fZ+6CnZWeZGvhqDVsn2/2XVZTLoe3wky5t73jmwt3F5B4EtZNMdPRUbDli6L3+2FvmGpdkDNT4afxJgiA6cpgo9Wi/PhGW42Y4xtNA8I3m5ky9jeawL6fITrS/K4OrYb/3gw//h+gTSOq+XfDmjdMEAA4sQWWvZA/L2veMC9nhSgVeVlcdq76Hd74ITTuZqYbd3Nco8iTTm2HKa1MJ11gypN/Gm9qG6XG2Zr6A5zZYy50nw0zfbXby86CuOOmyOJN6+56/zJYOLrokZSWPg8TrVoms4c7F3Byy72P/WF6jPx0sAkQCUU03PvkavjhKVuf7kd/s7VanVgDEuzGhd30se1CDeZFu73cbg12fWfK4tPibGXsi8fCJ4PM9NybSq4rH7unpCMVosLx7qIhV9Z97nKX+bEX8RBEbzY1Mpr0gOiLqDVS3n4cYz7/Wm+bt3Fm/gsimDvrT6yaJ8c2wJej4DFrm9y+3Ks1sK2fmWq7Uz+w3FSf7XZ//n1u+sh8vtPWtFgtaNci07I1+Wz++YvHQmSBzv6m94Tm/aBpD9u8D3vbprfMgSO/ws5vzferCnRadmBF/jL3khTssdJdLciFKIobSnSVvgQaikREROjIyMiL3/B/t5uaNY+uK3nd8rJjgenvvMXAwsPWXSpevmCKvIq6k79+mi3QALQeBt0egK9uM0Ej6XThbe5fCn/Oh5CGsPbNwsuFEI49sspW+nCRlFJRWuuIktbz7icCd7wjKCisr/kcMOHSDQSTSnhxax8EAPb/bH7AcRAAM8iIEKIUpGVx2bm7pkxIA9v7gmf2m/FKt8611Sn3C5S+g4QQFYp3BwJPF3uF1Dc/zXrDtZNNVcT0RNtLVyGEKIkbbmbdXmtIKdVUKbVaKbVHKbVLKVUOPcIVm6Jrd+9UFhQEV7d93vk1XO2gLvyId9yfNyFEBeeFgQDIAp7RWrcDegFPKKXal7BNKVXQF+Gth5pO7ArqUMSoT0KIiufat4teljtGw8W4ZyE061v6/JSB2wOB1vqU1nqLNZ0I7AEauyzBitiatqDHN5r3ClVKGJxDCFE2Q5zsoqPNcLjzG7hxOrx8Hq58Ep49kH+dnqPtph/NvyzUrsO/UZ/DizGF0+g9BoKt9jbPHjSDzxRsyQ5Qo4lzeS4DjzYoU0qFAV2AQuPLKaVGK6UilVKRsbGx7s6a61W1ug3o9zzUa+vZvAhxqfILgAl23Wd3tRtfYeCL0Ppa2/dhb8Hl15S8z7G7YORsaD0Eutxtev8c+jpUq2db585vbNONukD3R/Lvo5VdOm2vg8BgU+30WC7pAAAZ+0lEQVTa3pB/wYS/zE1gNet6cON0qNsaHttgAtA/z0HVuiXnuYw81o5AKVUNWAu8rrX+rrh1S92O4MxeU0OnQQXtXjctHoJCTJ39XBfT7YMQl6p+z8Ovkx0ve+GE6ZHVUQd7vcfA79NMP1rdH4Gu95j503uZVt0vnzcdCmZnmH6psjPhX9aF9PGN5qbr+CYzVjJAtfpQKyz/WMfF9RKQmWq6W8m9cGemmWDkH2AaSG75AtZPhfFHID2hcB9a66fCilfMGCmPrS+8/3LmbDsCjwQCpVQgsBhYprV+t6T1Sx0ILkULHjLjJ3x1u6dzIkT5C21n7q4vt7rtyEiBfzc009e+bYpUWvS3XTBzXTsZmvZ0PEgPmIvwqe22/dr7YYxpgT5uD1S3yu5zb7hGvAN/fm0LBKPXmDt8L1FhG5QppRTwKbDHmSDgc0Z+WvI6QpRV33GmC+yL8bdPocEV8N0jcGqbmTdqDnxzn22dh34xF9XsTIicDfHH4NYvoP2NjvcZVMW0ZD9/GOpebpsfUMl8th5meoTt+ffi81a1ruMgADB8itm+ut0L3H+cMmMBBwZD1Xomz/aBwse4/YlAKdUXWAfsAKyO2/mH1nppUdv41BNBroRT5o80LQHev8LTuRGXqhpNIf544fkT483QlJVr2cZGeGqLuQDPvxtObs2//rWT81+Mc++oJ8bDhunQagjUbAYBdoM2ZWfB/p9MGfnFVtrISje9tvZ7DoKqXty2Ik+FLhq6WD4ZCOytnWwbmER4p44jTc+mLa82Q5IWxz/IlIEDvBJnelf9fVrhC374XTD8bdgy1wxwY8++HHz7PFPmXq+d+a61GVxn/8+mVkvVUDM4iv3F/OAKCKgMYX1KdbjCPSQQeJu/NphxZ/cugUwZfeySdc0kMyQlwGO/wwyrJ9XcC/ORX2FOgTYm9/1om9fveeg71jwlPvQL1G5uWy/hFKx/z5TB71oEHW+xjXcbuw8+GWxeYFarD8/ud90xigpDAoG3So0ztR7+NwpQ8Pgf8GFPT+dKFOWGD+CHJ23fC9ZI+e19U2vFvgw9J8eUrUdHmk4MQxrYimL+ec7UUCmNDdNh2T/gn2fBP7B0+xCXlAr7sliUUeWaENraTPd+0lSHC6wKmcmezZcjHUfCzgVFLw+skv/pJiAY/r4OpncvvzxccZvp/toZlWubYTAXjzXfa7eEB5eZ8RdCGsCSZ0xd8lphsNQa9+CZ/VCpmhmHePs8U5XwysfNEJw622yXegF++ScMerlwmn0c9LDi52fSqBWWf37Hv5U+CIAZa9t+vG0hLPJEcKk6e9BcKPwDIOW8uRDt+BrqtDK1LKrUgd+mwravTKOY3CEewTRWmXGlmW4cASes322Hm22DuhdkXzxx44fw/eP5l19xO/w5z/b9ic2mw703L3O8v3sWmXF8v33YFixGrzXVAx21pSh4J21f/W/JM+bOu3JNM4hNbpoTjkGwtV52FmQkwVvNzPdn9sFH/eGh5WbIyewMGP+X2UfccXPHHNKAIu350TROCgwuep3ylJ0Jyj9/mxMhSiBPBN7Ovqpdldrm56pn8q8zeKL5AVPEMPcmqHM51G9vGt6kxkHVOraL6qjPwb+SuaB3fxhQZhjHgS+ZC2y1+pAUY6rpvXwBlow1LxW3fGHKojvfYetuu1o920UYzIX80Gq4rJepCRVS38wf+Sm0udbcNRdVR9xRZ3z9njcX6u4PQZsRUL2hbVnnO01Qs0/fP8Bc5P/2Kez4xmz77D6z7MlI0114Zau5f00neod11FeUK0lRjnAhCQS+ooFVBXXoG+bTz98EATAvLQOrmOnci2DrYabGyOaPbeXXN/wHVkyEKnXNnen175vW0eePQP/xUKsZ3DTD1DrJvXOt3wlidpjplgPNZ2Dl/HnrNDL/97bXmYDTYqBpfVrfQcvwq1+0TdsHAYCbZxT9e+g0snB6tZqZHyF8lBQNifyyM83g9G1HVIwO+xJPF19EI4QokhQNidLxD4R213k6FzYSBIRwOXnzJIQQPk4CgRBC+DgJBEII4eO8OhD8dS6Zg2eSPJ0Nt5i/+RjPL9ieb152juaRLyJ5fcluD+Wq9BZtPcG3UdGezoYQPsGrA8ErP+xi3NfbPJ2NcrE/JpFvo6LJys4hKzuHF777M1+QG//tDr6ONBfOzOwcftx+kpb/WMovu2P4eN0Rfjt4ljMJaWbdBX8yffVBAKIvpLDzRDwxCWkcOZvMvtOJReYhKT2LtfudGy0uIyuH4+eL7xMpJSMLrTU7T8STmZ2TN3/f6USenr+NZ77ZXszWxUvNyCYnp3xqxOXkaC6F2nVClJZX1xpSmCrtl6rUjGxeW7Kb8de2Zch7vwLkuzh+tcn0Nvn04FZ58z5bf4RJiws/Adz1yUYa1Qjmi4d6MD/SbNegenCRF9u/92uBv5/iuaFm7NUpy/fxbdQJTiek8fywNkz+2TTGWj9+IP9avJtJN3Zk5Z4z3NylMQ9/sZnfDp7L29f80b24bdYfhDetSWZ2Ds3rVuX+3mGMnLmBjo2rs/NEAmF1qjBuSBsSUjN5adHOvG3DJixh77+GcSYhnZDgAN79ZT/bo+OYdU8E01Yd4OvNxzn47+EALNt1mr/PjSLqpcF0e20FD/QJ45GrWjB6biQ7TySwZ9IwggP9SM3MplKAP9EXUggJDuSTdYe5MbwxbRrYxos9fj6FCykZXF6vGu1fXsYz17TmqUG233N6Vja/HzzHwLb1yM7RbDl2gTpVg/jrXAoD29oNaWg5l5TOk//byvt3hFMvxE2tkYVwkle3I3jo883EJKax+KmrXJAr1+v++gpiE9Np2yCEvcXcqXu7W7o05rutJ8q8n6uti/ba/bGEBAeQmJZVaJ1aVQK5kJKZ9/2hvs35dP0RGtUIZt34q5m28gB1qwXx4/ZTbDp6HoBhHRrw867TedtsenEQPV5fyTXt6/PL7hh+n3A130ZF884v+2lSqzK/PjeQGWsPMSqiicOgcCIuFT8FDWtULrQs19r9sVQJ8qd7WG3A3ABUDvLnjh6Fu/T4ftsJqgYFMLh9fed/WcIrSO+jwMNzNnMyLo2l/+eZQJCRlUNKRhZJ6Vn0fWs1d/W8jKEdGtCvdajD9U/GpdL7zVVMGdWZc0npvPHTXjfnWLhbv9ahnIxL5cSFVFo3CGH78bi8ZfWrVyImIT3v+2MDWjJjzSFeub49r/5onvreuKUTB88k8en6I4AJQtWDA0lMyyI0pBI/7zzNo/+NAuD7J/pQKdCPtg2qA6bISylQVsPBjKwc4lIyqFe9cHBKSMvkfFIGYXXLPkhMwXSF60ggAB6eE8mJuFR+8lAgePDzzazae4YqQf6kZGTnzZ91Tzf6tqpLQmoWDWqYf7ppKw/w7i/SR7xwv/6tQ0nLzGbjEfOEs/ipvuw4Ec+x8ykMblePqpUCeOy/WzhyNpkeYbXZdPQ8a54dQFjdqqRmZKMUBAf6k56VzTvL9zNmUCuqVSpc6rxm3xnaNqhOrzdW0qFRdb57vDeBfn74+eUPCKv3neGB2Zt5flgbHuvfssiAsXBrNL/uP8t7txXRR5XlfHIG24/HOSyy83YSCIBHvojk+PkUfn66nwtyVdiZxDQ+XH2Il0a0I8Dfj7AJS0rcJijAj2va1WfJjlNuyKEQ5efF4e14fekeh8tm3t2NST/u4stHejFwypoi9zGobT3euKUTPf69konXt6d65UB+2H6SNftslRJu7tKYZ4e2wV8pXv1xF78fOkd8qq34bsfEIeTkgEaTkpGd91R9feeGVArw56bpv7HteBw7Jg4hM1tTq0ogSiniUjKYvvog2Tmw7fgFvnv84kdbOxCTSEpGNp2b1rzobX/ZHcPphDTu6WXr5yonR5OWlU2VoPJ5fSuBAPj73Ej+Oue+QND7jZWcjE+jUY1gpt/VlZs//N0t6QohHGtRtyqHz+Yfq+Ppwa34eefpQu/d1j0/kCU7TlGzciDhl9WkTf0Qlu44zVWt63LNu2t599Zwvo48TrM6VRnaoT4dGtXId7Pnp6BFaDUOnkninVGdGXFFQ9r+82euaV+fHmG1qRsSRPew2sQkpPO3GbZrQ8/mtZn/9ytJSs/i/77aysq9Z5jzYA/u+2wTk/92Bbd2d6I33CJIIAAenRvF4bNJLB/b3wW5Mk7Hp3HT9N84bVXNFEKI8nT0zRGl3tbZQODV7QiUck310VPxqYRNWMLyXafp9cZKCQJCCJfJyMopeaUy8upA4KcUrnjeGTff1L0fPTfKBXsXQgibPacSXJ6GVwcCFOSUwyNBWmY2aZm2Wj8XUjLKvE8hhHBGqt21x1W8vmXx4dhktNZlqrPc9p8/oxQMbFOPLk1rVujGXVe1qkuTWpXzWh0XVKtKIN88eiXLdsXw9rJ9efPv6NGUrzYd5+Xr2vOg1YjqX4t3c1tEU8YMbkVIcACbj5zndEIad/VslveSbMzVlzNt1UHWPDuAhLRMFIrrP1gPwIYXTAOsSTd2JEdrKgX4k5CWyYrdMYz72taiefFTfWnfsDq7TyUQ4K8YNnUdXS+ryZZjpk79nT0vY0j7+gxoU4+cHM1PO08zffVBdp9K4OibI8jMzuHjdYe5kJzBgDb1uOuTjXn7fv/2cHadTGDWr4dZMqYvTWtXYdbaw3xgdbFhLyQ4gHHXtObgmSSCA/35dP0Rbu7SmAA/xTfS75HwkINnkujVoo5L0/Dql8WdJi4jMS2LR65qzosj2pc6fWeqgbrLsA4NmHlPt7w8HXljuMMgF5+Sydw/jjJluWmbcPTNEaRkZBHk70eAvx/bjsdx0/Tf8ta/2BdSJ+NSiUvJpH2j6oWWxSamcy45Pa/hkiM3fLCe3i3rMuHatheVrjNiE9MJCvCjRuWSx/lNy8xmzu9HGRXRlNpVg5xOIztH8/22E3mteysH+fPZ+iMMbFuPkEqBLNx6gvt6N+N8cgZTVxzg9h5NeWnhTg6fTebrv19JSHBAXjuXgoZ3asDSHafzzWvXsDp7TiXQpn4I+2Iq7o2IKH//fagnfVvVLdW2UmuI/Bfw0r55j0vJIHzSL6Xatjw8PqAlDWoEc1fPZmyPjqPrZbXy8qWUKvFit/NEPL8dPMvf+7cstExrTXpWTl4rVOF+h2OTaBFa7aK2+etcMkEBfjSwWgDvPZ3IH4fP8UCf5qzYHUP0hRTqVQ9m67ELfLzOtDiedkcXtNbUrVaJw7FJBAX48dHawxw+m0y1SgEkpWdxf+8wujarxZivttK/dWheB4MSfDxr84uDS/3/KYEA5wLBrpPxTP55Hy1DqzG6X4u8lr5gevx8eE4kx0roRbM8LXqiT96delmqjQkBEJ+aWezNQmJaJgF+flQO8i+07GRcKrWrBhEc6M/243FsOHyObs1q5fVvlJWdQ1aOJjjQn3NJ6dSsEkRKRhZxKZn8eiCWFxfaOg8M8vdjWMcGpGdl075hDSLCavHbwbNsj47L10GhKMwd1Ud9PhAULPapHOhPamY2g9vVY8WeMxedZlnIhV94m4S0TD5cfYhnhrQm0N9x3ZSs7Bz8/VS+Is6lO05xeb1qtK4fkm/dpPQssrM1vx6IZXinhhw7n0JYnSqcTkhj5Z4zvLRoJ8ue7kebBiEciEkkKMCP6sGB1LKK/Q7EJDJ/83GeuroVNaoE5isu/TM6jneW7+f4hRSS07OISUinfvVKPDnwclbvi2VUtybsj0kiNKQS1SsH0KlxDdIyc/jbjN9JSs/Ke18G8PXfr+TWjzYAsOzpfnwdeZxB7erxTWQ0/7qpIx1fWZbvuCoF+HFHj8v4/PejhX4/Eggs5R0IwiYsoWaVQLa9PMQt5f+9W9bBTynWHzybl5cDMYlcXq+adLwlhI9Kz8rmVFyaw478YhPTuea9tUy7vUuRnVQ6w9lA4NW1hooTZ9fVsCs8PqAlj1zVIu9OBMyLyeR00/VxqwJ3OkII31IpwL/I3lxDQyqx7eUhbsuLRwKBUmoY8D7gD3yitX7TFekU7PUTyDfS1NPztpZbWle1qsvl9aox5/ejHH7D8aNccKA/wYGFy2KFEMKT3N6gTCnlD0wHrgXaA3copUpft7MY9kEg+kIKp+PTuO2jP/LmLdp2stT7Xvh473zf5z7Uk1eu71BkEBBCiIrKE08EPYCDWuvDAEqpecCNgEtHWO/71uoy7+OFa9tSp1oleresQ6OalTn65gjiUzMJcdD3uhBCXCo8cQVrDNg3e40GenogH/k0qhHMyfjCnce9d1tnrm5TnxpVHFfBc6bRkhBCVGSeCASOqskUqrqklBoNjAa47LLC47A6Y93zAzl4JokHPt9c5DrbXx5S5EVeCCF8gScCQTRgP9JCE6BQYb3WehYwC0z10dIk1LR2FZrWriL184UQohie6H10M9BKKdVcKRUE3A784IF8CCGEwANPBFrrLKXUk8AyTPXRz7TWu9ydDyGEEIZHqrtorZcCSz2RthBCiPy8e2AaIYQQJZJAIIQQPk4CgRBC+DgJBEII4eMkEAghhI+7JMYjUErFAn+VcvO6wNlyzM6lQI7ZN8gxe7+yHm8zrXWJAxpcEoGgLJRSkc4MzOBN5Jh9gxyz93PX8UrRkBBC+DgJBEII4eN8IRDM8nQGPECO2TfIMXs/txyv178jEEIIUTxfeCIQQghRDK8OBEqpYUqpfUqpg0qpCZ7Oz8VQSjVVSq1WSu1RSu1SSv2fNb+2UuoXpdQB67OWNV8ppaZZx/qnUqqr3b7us9Y/oJS6z25+N6XUDmubaUopR4MGuZ1Syl8ptVUptdj63lwptdHK/3yr+3KUUpWs7wet5WF2+3jBmr9PKTXUbn6F+5tQStVUSi1QSu21zveV3n6elVJjrb/rnUqpr5RSwd52npVSnymlziildtrNc/l5LSqNYmmtvfIH08X1IaAFEARsB9p7Ol8Xkf+GQFdrOgTYD7QHJgMTrPkTgLes6eHAT5gR4HoBG635tYHD1mcta7qWtWwTcKW1zU/AtZ4+bitf44D/AYut718Dt1vTM4HHrOnHgZnW9O3AfGu6vXW+KwHNrb8D/4r6NwHMAR62poOAmt58njHD1R4BKtud3/u97TwD/YCuwE67eS4/r0WlUWxePf1P4MKTcCWwzO77C8ALns5XGY7ne+AaYB/Q0JrXENhnTX8E3GG3/j5r+R3AR3bzP7LmNQT22s3Pt54Hj7MJsBK4Glhs/ZGfBQIKnlfMmBZXWtMB1nqq4LnOXa8i/k0A1a2Loiow32vPM7Zxy2tb520xMNQbzzMQRv5A4PLzWlQaxf14c9FQ7h9brmhr3iXHehTuAmwE6mutTwFYn/Ws1Yo63uLmRzuY72lTgeeBHOt7HSBOa51lfbfPZ96xWcvjrfUv9nfhSS2AWGC2VRz2iVKqKl58nrXWJ4ApwDHgFOa8ReHd5zmXO85rUWkUyZsDgaNy0EuuipRSqhrwLfC01jqhuFUdzNOlmO8xSqnrgDNa6yj72Q5W1SUsu2SOGXOH2xWYobXuAiRjHueLcskfs1VmfSOmOKcRUBW41sGq3nSeS+LRY/TmQBANNLX73gQ46aG8lIpSKhATBL7UWn9nzY5RSjW0ljcEzljzizre4uY3cTDfk/oANyiljgLzMMVDU4GaSqnc0fTs85l3bNbyGsB5Lv534UnRQLTWeqP1fQEmMHjzeR4MHNFax2qtM4HvgN5493nO5Y7zWlQaRfLmQLAZaGXVRAjCvGT6wcN5cppVA+BTYI/W+l27RT8AuTUH7sO8O8idf69V+6AXEG89Fi4Dhiilall3YkMw5aengESlVC8rrXvt9uURWusXtNZNtNZhmPO1Smt9F7AaGGmtVvCYc38XI631tTX/dqu2SXOgFebFWoX7m9BanwaOK6XaWLMGAbvx4vOMKRLqpZSqYuUp95i99jzbccd5LSqNonnypZEbXtQMx9S2OQS86On8XGTe+2Ie9f4Etlk/wzFloyuBA9ZnbWt9BUy3jnUHEGG3rweBg9bPA3bzI4Cd1jYfUOCFpYePfwC2WkMtMP/gB4FvgErW/GDr+0FreQu77V+0jmsfdrVkKuLfBBAORFrnehGmdohXn2fgVWCvla+5mJo/XnWega8w70AyMXfwD7njvBaVRnE/0rJYCCF8nDcXDQkhhHCCBAIhhPBxEgiEEMLHSSAQQggfJ4FACCF8nAQCIVxAKTVAWb2nClHRSSAQQggfJ4FA+DSl1N1KqU1KqW1KqY+UGQshSSn1jlJqi1JqpVIq1Fo3XCn1h9Vf/EK7vuQvV0qtUEptt7Zpae2+mrKNM/ClXX/xbyqldlv7meKhQxcijwQC4bOUUu2A24A+WutwIBu4C9MJ2hatdVdgLfCKtckXwHit9RWY1p+5878EpmutO2P6zDllze8CPI3pN78F0EcpVRu4Gehg7ec11x6lECWTQCB82SCgG7BZKbXN+t4C0wX2fGud/wJ9lVI1gJpa67XW/DlAP6VUCNBYa70QQGudprVOsdbZpLWO1lrnYLoICQMSgDTgE6XULUDuukJ4jAQC4csUMEdrHW79tNFaT3SwXnH9sBQ37GO63XQ2ZtCVLKAHplfZm4CfLzLPQpQ7CQTCl60ERiql6kHeWK/NMP8Xub1g3gms11rHAxeUUldZ8+8B1mozRkS0Uuomax+VlFJVikrQGl+ihtZ6KabYKNwVBybExQgoeRUhvJPWerdS6iVguVLKD9NL5BOYwWE6KKWiMKNh3WZtch8w07rQHwYesObfA3yklJpk7WNUMcmGAN8rpYIxTxNjy/mwhLho0vuoEAUopZK01tU8nQ8h3EWKhoQQwsfJE4EQQvg4eSIQQggfJ4FACCF8nAQCIYTwcRIIhBDCx0kgEEIIHyeBQAghfNz/A2p2+OZdQc0FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d25cb1e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(DLoss, label = 'Discriminator Loss')\n",
    "plt.plot(GLoss, label = 'Generator Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
